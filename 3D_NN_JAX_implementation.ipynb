{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIR', 'Indata', 'Jac', 'SE', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__firstlineno__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', 'i']\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "\n",
    "with open(data_file,\"rb\") as f:\n",
    "    data_unpickled = pickle.load(f)\n",
    "\n",
    "data_index,data_object = data_unpickled\n",
    "\n",
    "print(dir(data_object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31190a3b",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a88165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "\n",
    "base_key = jax.random.PRNGkey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a6f5b",
   "metadata": {},
   "source": [
    "Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb139a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 1000\n",
    "alpha = 1.0\n",
    "gamma = 1.0\n",
    "lambda_ = 1.0\n",
    "Learn_Rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.module):\n",
    "    \"\"\"Model architecture\"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int,dim_hidden3_in, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in, rngs=rngs)\n",
    "        self.layer3 = Linear(din=dim_hidden2_in,dout=dim_hidden3_in)\n",
    "        self.layer4 = Linear(din=dim_hidden3_in,dout=dim_out)\n",
    "        self.silu = SiLU()\n",
    "        \n",
    "    def __call__(self,x_in):\n",
    "        # pass to calculate e\n",
    "        def forwardPass(x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer4(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "        e = forwardPass(x_in)\n",
    "\n",
    "        # pass to calculate e_prime\n",
    "        dedx = jax.grad(forwardPass,argnums=(0))\n",
    "        e_prime = dedx(x_in)\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, model,alpha,gamma,lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    prediction_e, prediction_e_prime = model(x)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime)**2)\n",
    "    target_zero = 0\n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "\n",
    "    prediction_zero, _ = model(x_zero)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    def __init__(self,model,params,optimiser,opt_state,alpha,gamma,lambda_):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.optimiser = optimiser\n",
    "        self.opt_state = opt_state\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.lambda_ = lambda_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(TrainState,batch,loss_fn):\n",
    "    Model = TrainState.model\n",
    "    params = TrainState.params\n",
    "    optimiser = TrainState.optimiser\n",
    "    opt_state = TrainState.opt_state\n",
    "    alpha = TrainState.alpha\n",
    "    gamma = TrainState.gamma\n",
    "    lambda_ = TrainState.lambda_\n",
    "\n",
    "    strain_in, e_target, e_prime_target = batch\n",
    "\n",
    "    def wrapped_loss_fn(Model):\n",
    "        loss = loss_fn(\n",
    "            strain_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss = loss_fn(strain_in,e_target,e_prime_target,Model,alpha=alpha,gamma=gamma,lam=lambda_)\n",
    "    grads = nnx.grad(wrapped_loss_fn)(Model)\n",
    "\n",
    "    updates, new_opt_state = optimiser.update(grads.parameters(), opt_state, Model.parameters())\n",
    "    nnx.apply_updates(Model.parameters(), updates)\n",
    "\n",
    "    new_state = TrainState.replace(opt_state=new_opt_state)\n",
    "    return new_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=9, \n",
    "    dim_hidden1_in=1024,\n",
    "    dim_hidden2_in=512,\n",
    "    dim_hidden3_in=124, \n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    "    )\n",
    "\n",
    "params = nnx.get_parameters(Model) \n",
    "\n",
    "opt_state = optimiser.init(params)\n",
    "train_state = TrainState(\n",
    "    model=Model,\n",
    "    params=params,\n",
    "    optimiser=optimiser,\n",
    "    opt_state=opt_state\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in Epochs:\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        new_state, loss_batch = training_step(TrainState,batch,loss_fn)\n",
    "\n",
    "        running_loss += loss_batch\n",
    "    \n",
    "    loss_record.append(running_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
