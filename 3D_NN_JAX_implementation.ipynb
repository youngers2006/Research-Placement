{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(20000, 152, 3)\n",
      "(20000, 1)\n",
      "(20000, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = jnp.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a6f5b",
   "metadata": {},
   "source": [
    "Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb139a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 1000\n",
    "alpha = 1.0\n",
    "gamma = 0.4\n",
    "lambda_ = 0.1\n",
    "Learn_Rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4221141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING RAW DATASET\n",
      "Key: 'displacements'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (20000, 456)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (20000,)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e_prime'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (20000, 456)\n",
      "  - Dtype: float32\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "# input_dataset target_e_dataset target_e_prime_dataset \n",
    "\n",
    "input_dataset = input_dataset.reshape((20000,456))\n",
    "target_e_dataset = target_e_dataset.reshape((20000,))\n",
    "target_e_prime_dataset = target_e_prime_dataset.reshape((20000,456))\n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset,\n",
    "    'target_e':target_e_dataset,\n",
    "    'target_e_prime':target_e_prime_dataset\n",
    "}\n",
    "\n",
    "print(\"INSPECTING RAW DATASET\")\n",
    "for key, value in Dataset.items():\n",
    "    print(f\"Key: '{key}'\")\n",
    "    print(f\"  - Type: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  - Shape: {value.shape}\")\n",
    "    else:\n",
    "        print(\"  - No shape attribute.\")\n",
    "    if hasattr(value, 'dtype'):\n",
    "        print(f\"  - Dtype: {value.dtype}\")\n",
    "print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.Module):\n",
    "    \"\"\"Model architecture\"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int,dim_hidden3_in, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in,rngs=rngs)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in,rngs=rngs)\n",
    "        self.layer3 = Linear(din=dim_hidden2_in,dout=dim_hidden3_in,rngs=rngs)\n",
    "        self.layer4 = Linear(din=dim_hidden3_in,dout=dim_out,rngs=rngs)\n",
    "        self.silu = SiLU\n",
    "        \n",
    "    def __call__(self,x_in):\n",
    "        # pass to calculate e\n",
    "        def forwardPass(x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer4(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "        e = jax.vmap(forwardPass)(x_in)\n",
    "        dedx = jax.vmap(jax.grad(forwardPass,argnums=(0)))\n",
    "        e_prime = dedx(x_in)\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, Model,alpha,gamma,lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(x)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime)**2)\n",
    "\n",
    "    target_zero = 0\n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "    prediction_zero, _ = Model(x_zero)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any \n",
    "    state: Any\n",
    "    alpha: float \n",
    "    gamma: float \n",
    "    lambda_: float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(params,state,opt_state,batch,*,graph_def,alpha,gamma,lambda_):\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(params_,state_):\n",
    "        Model = nnx.merge(graph_def,params_,state_)\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model=Model,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=0)(params, state) \n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "\n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e88cb1",
   "metadata": {},
   "source": [
    "Batch Creator and test set creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9981b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_batch_dataset(dataset, batch_size, test_split=0.2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets, then yields batches for each.\n",
    "    Returns: (train_batches, test_batches).\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    split_idx = int(N * (1 - test_split))\n",
    "    train_idx = indices[:split_idx]\n",
    "    test_idx = indices[split_idx:]\n",
    "\n",
    "    def batch_indices(idx):\n",
    "        batch_num = len(idx) // batch_size\n",
    "        for i in range(batch_num):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            batch = {key: value[batch_idx] for key, value in dataset.items()}\n",
    "            yield batch\n",
    "\n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e467e7e",
   "metadata": {},
   "source": [
    "Create test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df10eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = split_and_batch_dataset(\n",
    "    Dataset, \n",
    "    Batch_size, \n",
    "    test_split=0.2, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1], \n",
    "    dim_hidden1_in=512,\n",
    "    dim_hidden2_in=256,\n",
    "    dim_hidden3_in=64, \n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    lambda_=lambda_\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(train_batches,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        \n",
    "        new_params, new_state, new_opt_state, loss_batch = training_step(\n",
    "            train_state.params,\n",
    "            train_state.state,\n",
    "            opt_state,\n",
    "            batch,\n",
    "            graph_def=train_state.graph_def,\n",
    "            alpha=train_state.alpha,\n",
    "            gamma=train_state.gamma,\n",
    "            lambda_=train_state.lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e850b4",
   "metadata": {},
   "source": [
    "Final model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0738a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class ModelData(nnx.Object):\n",
    "    graph_def: Any\n",
    "    params: Any\n",
    "    state: Any\n",
    "    trained: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b354",
   "metadata": {},
   "source": [
    "Create Final model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78303138",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_trained = train_state.graph_def\n",
    "params_trained = train_state.params\n",
    "state_trained = train_state.state\n",
    "\n",
    "model_data = ModelData(\n",
    "    graph_def=graph_def_trained,\n",
    "    params=params_trained,\n",
    "    state = state_trained,\n",
    "    trained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80f93141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x166608c4050>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(jnp.log10(jnp.array(loss_record)))\n",
    "plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4b0a9",
   "metadata": {},
   "source": [
    "Eval State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d94470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61baeb33",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_abs_error(pred,target):\n",
    "    n1 = pred.shape[0]\n",
    "    n2 = target.shape[0]\n",
    "\n",
    "    if n1 != n2:\n",
    "        raise(\"Error: inputs must have matching shape\")\n",
    "    \n",
    "    return (jnp.sum(jnp.abs(pred - target)) / n1)\n",
    "\n",
    "def test_model(model_data, test_batches,*,loss_fn, alpha, gamma, lambda_):\n",
    "\n",
    "    trained = model_data.trained\n",
    "    if not trained:\n",
    "        raise TypeError(\"Model is untrained, please train the model before evaluation\")\n",
    "\n",
    "    test_graph_def = model_data.graph_def\n",
    "    test_params = model_data.params\n",
    "    test_state = model_data.state\n",
    "\n",
    "    test_model = nnx.merge(test_graph_def,test_params,test_state)\n",
    "\n",
    "    loss_test = 0.0\n",
    "    test_count = 0\n",
    "\n",
    "    for batch in test_batches:\n",
    "        displacements_test = batch['displacements']\n",
    "        e_target_test = batch['target_e']\n",
    "        e_prime_target_test = batch['target_e_prime']\n",
    "\n",
    "        e_pred_test, e_prime_pred_test = test_model(displacements_test)\n",
    "\n",
    "        batch_loss_test = loss_fn(\n",
    "            displacements_test,\n",
    "            e_target_test,\n",
    "            e_prime_target_test,\n",
    "            Model=test_model,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        loss_test += batch_loss_test\n",
    "        test_count += 1\n",
    "\n",
    "        avg_e_abs_error = avg_abs_error(e_pred_test,e_target_test)\n",
    "        avg_e_prime_abs_error = avg_abs_error(e_prime_pred_test,e_prime_target_test)\n",
    "\n",
    "    avg_loss_test = loss_test / test_count\n",
    "    zero_val_e, _ = test_model(jnp.zeros_like(test_batches[0]['displacements']))\n",
    "    test_e_zero_error = avg_abs_error(zero_val_e, jnp.zeros_like(zero_val_e))\n",
    "\n",
    "    return avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3504",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1486d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss across the training set is 183980608.0\n",
      "The average absolute error for e is 115.9399642944336\n",
      "the average absolute error for e prime is 4632243.0\n",
      "the absolute zero error for e is 260.93914794921875\n"
     ]
    }
   ],
   "source": [
    "avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error, test_e_prime_zero_error = test_model(model_data,test_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    "print(f\"The average loss across the training set is {avg_loss_test}\") \n",
    "print(f\"The average absolute error for e is {avg_e_abs_error}\") \n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error}\") \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
