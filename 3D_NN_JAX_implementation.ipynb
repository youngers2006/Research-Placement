{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(20000, 152, 3)\n",
      "(20000, 1)\n",
      "(20000, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = np.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0081196",
   "metadata": {},
   "source": [
    "Create Batches function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(dataset, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Creates data batches for training\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    \n",
    "    for start in range(0, N, batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_idx = indices[start:end]\n",
    "        \n",
    "        yield {\n",
    "            key: value[batch_idx]\n",
    "            for key, value in dataset.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "\n",
    "base_key = jax.random.PRNGkey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a6f5b",
   "metadata": {},
   "source": [
    "Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9eb139a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 1000\n",
    "alpha = 1.0\n",
    "gamma = 1.0\n",
    "lambda_ = 1.0\n",
    "Learn_Rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4221141",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "# input_dataset target_e_dataset target_e_prime_dataset \n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset,\n",
    "    'target_e':target_e_dataset,\n",
    "    'target_e_prime':target_e_prime_dataset\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.module):\n",
    "    \"\"\"Model architecture\"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int,dim_hidden3_in, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in, rngs=rngs)\n",
    "        self.layer3 = Linear(din=dim_hidden2_in,dout=dim_hidden3_in)\n",
    "        self.layer4 = Linear(din=dim_hidden3_in,dout=dim_out)\n",
    "        self.silu = SiLU()\n",
    "        \n",
    "    def __call__(self,x_in):\n",
    "        # pass to calculate e\n",
    "        def forwardPass(x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer4(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "        e = forwardPass(x_in)\n",
    "\n",
    "        # pass to calculate e_prime\n",
    "        dedx = jax.grad(forwardPass,argnums=(0))\n",
    "        e_prime = dedx(x_in)\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, model,alpha,gamma,lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    prediction_e, prediction_e_prime = model(x)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime)**2)\n",
    "    target_zero = 0\n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "\n",
    "    prediction_zero, _ = model(x_zero)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    def __init__(self,model,params,optimiser,opt_state,alpha,gamma,lambda_):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.optimiser = optimiser\n",
    "        self.opt_state = opt_state\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.lambda_ = lambda_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(TrainState,batch,loss_fn):\n",
    "    Model = TrainState.model\n",
    "    optimiser = TrainState.optimiser\n",
    "    opt_state = TrainState.opt_state\n",
    "    alpha = TrainState.alpha\n",
    "    gamma = TrainState.gamma\n",
    "    lambda_ = TrainState.lambda_\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(Model):\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss = loss_fn(\n",
    "        disp_in,\n",
    "        e_target,\n",
    "        e_prime_target,Model,\n",
    "        alpha=alpha,gamma=gamma,\n",
    "        lam=lambda_\n",
    "    )\n",
    "    grads = nnx.grad(wrapped_loss_fn)(Model)\n",
    "    updates, new_opt_state = optimiser.update(grads.parameters(), opt_state, Model.parameters())\n",
    "    nnx.apply_updates(Model.parameters(), updates)\n",
    "\n",
    "    new_state = TrainState.replace(\n",
    "        model=Model,\n",
    "        opt_state=new_opt_state,\n",
    "        params=TrainState.params,\n",
    "        optimiser=optimiser,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        lambda_=lambda_\n",
    "    )\n",
    "    return new_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1] * input_dataset.shape[2], \n",
    "    dim_hidden1_in=2024,\n",
    "    dim_hidden2_in=1012,\n",
    "    dim_hidden3_in=212, \n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    "    )\n",
    "\n",
    "params = nnx.get_parameters(Model) \n",
    "opt_state = optimiser.init(params)\n",
    "train_state = TrainState(\n",
    "    model=Model,\n",
    "    params=params,\n",
    "    optimiser=optimiser,\n",
    "    opt_state=opt_state\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in Epochs:\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(get_batches(Dataset, batch_size=Batch_size, shuffle=True),desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        new_state, loss_batch = training_step(TrainState,batch,loss_fn)\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f93141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
