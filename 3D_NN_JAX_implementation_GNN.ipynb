{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "import jraph\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab417de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c01a34",
   "metadata": {},
   "source": [
    "Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e18c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 500\n",
    "alpha = 1.0\n",
    "gamma = 1.0\n",
    "lambda_ = 1.0\n",
    "beta_1 = 0.999\n",
    "beta_2 = 0.9\n",
    "batch_size = 40\n",
    "train_split = 0.9\n",
    "CV_split = 0.05\n",
    "test_split = 0.05\n",
    "Learn_Rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5434d",
   "metadata": {},
   "source": [
    "RNG Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffad2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a000bf0",
   "metadata": {},
   "source": [
    "Standardising functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ecfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data = data[:split_idx]\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "\n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e91678",
   "metadata": {},
   "source": [
    "Create graph from mesh function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_known(cells, points):\n",
    "    # The faces of a cube based on its points\n",
    "    faces_of_cube = [[0, 1, 5, 4], [1, 2, 6, 5], [2, 3, 7, 6],\n",
    "                       [3, 0, 4, 7], [0, 1, 2, 3], [4, 5, 6, 7]]\n",
    "    \n",
    "    # construct faces\n",
    "    faces = []\n",
    "    for cell in cells:\n",
    "        for face_points in faces_of_cube:\n",
    "            face = [cell[i] for i in face_points]\n",
    "            faces.append(face)\n",
    "\n",
    "    # identify faces that only appear once and are therefore edge faces\n",
    "    edge_faces = []\n",
    "    for face in faces:\n",
    "        count = jnp.sum((faces==face))\n",
    "        if count == 1:\n",
    "            edge_faces.append(face)\n",
    "    \n",
    "    # deconstruct edge faces into a set of edge points\n",
    "    edge_points = set()\n",
    "    for edge_face in edge_faces:\n",
    "        for point in edge_face:\n",
    "            edge_points.add(point)\n",
    "\n",
    "    # for all edge points the displacement is known so construct the is_known feature as such\n",
    "    is_known = jnp.zeros(points.shape[0]) \n",
    "    for point in range(edge_points):\n",
    "        is_known[point] = 1\n",
    "    return is_known, edge_points\n",
    "\n",
    "def build_send_receive(cells):\n",
    "    sender_array = []\n",
    "    receiver_array = []\n",
    "    for edge in combinations(cells):\n",
    "        sender_array.append(edge[0])\n",
    "        receiver_array.append(edge[1])\n",
    "    return sender_array, receiver_array\n",
    "\n",
    "def build_graph(cells, points, U) -> jraph.GraphsTuple:\n",
    "    is_known, _ = Get_known(cells,points)\n",
    "    node_features = jnp.concatenate([points, U, is_known], axis=1)\n",
    "    sender_array, receiver_array = build_send_receive(cells)\n",
    "    num_nodes = points.shape[0]\n",
    "\n",
    "    graph = jraph.GraphsTuple(\n",
    "        nodes=node_features,\n",
    "        senders=sender_array,\n",
    "        receivers=receiver_array,\n",
    "        edges=None,\n",
    "        globals=None,\n",
    "        n_node=jnp.array([num_nodes]),\n",
    "        n_edge=jnp.array([len(sender_array)])\n",
    "    )\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c22883",
   "metadata": {},
   "source": [
    "Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Silu(x: nnx.Array) -> nnx.Array:\n",
    "    return x * nnx.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255c09c",
   "metadata": {},
   "source": [
    "Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399db1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"\n",
    "    Applies trainable linear transformation to input vector x\n",
    "    Inputs: x: din dimensional row vectors as matrix\n",
    "    Return: Transformed dout dimensional vector\n",
    "    Trainable Params: w: d dimensional row vector, b: d dimensional row vector\n",
    "    \"\"\"\n",
    "    def __init__(self, din: int, dout: int,*, rngs: nnx.Rngs):\n",
    "        self.din, self.dout = din, dout\n",
    "        key = rngs.params()\n",
    "        initialiser = nnx.initializers.lecun_normal()\n",
    "        self.w = nnx.Param(initialiser(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(initialiser(key=key, shape=(dout,)))\n",
    "    \n",
    "    def __call__(self, x: jnp.Array):\n",
    "        return x @ self.w + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615042f",
   "metadata": {},
   "source": [
    "GAT Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1030d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nnx.Module):\n",
    "    def __init__(self, in_features, out_features,*,rngs):\n",
    "        key = rngs.params()\n",
    "        initialiser = nnx.initializers.lecun_normal()\n",
    "        self.W = nnx.Param(initialiser(key=key, shape=(in_features, out_features)))\n",
    "        self.A = nnx.Param(initialiser(key=key, shape=(2 * out_features, 1)))\n",
    "        self.SoftMax = jraph.segment_softmax()\n",
    "        self.Leaky_Relu = nnx.leaky_relu()\n",
    "\n",
    "    def __call__(self, graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "\n",
    "        if graph.n_node is None:\n",
    "            raise ValueError(\"GAT requires nodes to have features\")\n",
    "        \n",
    "        h_sender = graph.nodes[graph.senders] @ self.W\n",
    "        h_receiver = graph.nodes[graph.receivers] @ self.W\n",
    "\n",
    "        send_receive_features = jnp.concatenate([h_sender, h_receiver], axis=-1)\n",
    "        attention_scores = self.Leaky_Relu(send_receive_features @ self.A)\n",
    "        \n",
    "        attention_coefficients = self.SoftMax(\n",
    "            logits=attention_scores, \n",
    "            segments_ids=graph.receivers,\n",
    "            num_segments=graph.n_node\n",
    "        )\n",
    "\n",
    "        weighted_features = attention_coefficients * h_sender\n",
    "\n",
    "        aggregate_nodes = jraph.aggregate_edges_for_nodes(\n",
    "            graph=graph,\n",
    "            edge_features=weighted_features,\n",
    "            aggregate_fn=jnp.sum\n",
    "        )\n",
    "\n",
    "        return graph._replace(nodes=aggregate_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045c04d",
   "metadata": {},
   "source": [
    "SAGPool WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a377c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGPool(nnx.Module): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314af953",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nnx.Module):\n",
    "    def __init__(self, input_dim: int, embedding_dim: int, output_dim: int, rngs: nnx.Rngs):\n",
    "        self.embedding_layer = Linear(input_dim, embedding_dim, rngs=rngs)\n",
    "        self.decoding_layer = Linear(embedding_dim, output_dim, rngs=rngs)\n",
    "\n",
    "        self.ReLU = nnx.relu()\n",
    "\n",
    "        self.encoderL1 = GAT(embedding_dim, embedding_dim, rngs=rngs)\n",
    "        self.BatchNormL1 = nnx.BatchNorm(num_features=embedding_dim, rngs=rngs)\n",
    "        self.encoderL2 = GAT(embedding_dim, embedding_dim, rngs=rngs)\n",
    "        self.BatchNormL2 = nnx.BatchNorm(num_features=embedding_dim, rngs=rngs)\n",
    "        self.encoderL3 = GAT(embedding_dim, embedding_dim, rngs=rngs)\n",
    "    \n",
    "    def embedder(self, graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "        nodes = graph.nodes\n",
    "        embeddings = self.embedding_layer(nodes)\n",
    "        return graph._replace(nodes=embeddings)\n",
    "    \n",
    "    def apply_activation_and_res(self, graph: jraph.GraphsTuple, residual: nnx.Array) -> jraph.GraphsTuple:\n",
    "        nodes = graph.nodes\n",
    "        activated_nodes = self.ReLU(nodes) + residual\n",
    "        return graph._replace(nodes=activated_nodes)\n",
    "    \n",
    "    def apply_res(self, graph: jraph.GraphsTuple, residual: nnx.Array):\n",
    "        new_nodes = graph.nodes + residual\n",
    "        return graph._replace(nodes=new_nodes)\n",
    "        \n",
    "    def decoder(self, graph: jraph.GraphsTuple) -> jraph.GraphsTuple: # Switch to SAGPool when its finished\n",
    "        aggregate_nodes = jraph.aggregate_nodes(graph, jnp.sum)\n",
    "        return self.decoding_layer(aggregate_nodes)\n",
    "        \n",
    "    def forward_pass(self, G: jraph.GraphsTuple, use_running_average: bool) -> nnx.Array:\n",
    "        G = self.embedder(G)\n",
    "        res1 = G.nodes\n",
    "\n",
    "        G = self.encoderL1(G)\n",
    "        self.BatchNormL1.use_running_average = use_running_average\n",
    "        nodes_norm = self.BatchNormL1(G.nodes)\n",
    "        G = G._replace(nodes=nodes_norm)\n",
    "        G = self.apply_activation_and_res(G, res1)\n",
    "        res2 = G.nodes\n",
    "\n",
    "        G = self.encoderL2(G)\n",
    "        self.BatchNormL2.use_running_average = use_running_average\n",
    "        nodes_norm = self.BatchNormL2(G.nodes)\n",
    "        G = G._replace(nodes=nodes_norm)\n",
    "        G = self.apply_activation_and_res(G, res2)\n",
    "        res3 = G.nodes\n",
    "\n",
    "        G = self.encoderL3(G)\n",
    "        G = self.apply_res(G, res3)\n",
    "\n",
    "        e = self.decoder(G)\n",
    "        return e\n",
    "    \n",
    "    def __call__(self, G: jraph.GraphsTuple, use_running_average):\n",
    "\n",
    "        e = self.forward_pass(G, use_running_average)\n",
    "        grad_graph = jax.grad(self.forward_pass, argnums=0)(G, use_running_average)\n",
    "        e_prime = grad_graph.nodes[:,4:7]\n",
    "\n",
    "        return e, e_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9615288",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.chain(\n",
    "    optax.add_decayed_weights(weight_decay=1e-5),\n",
    "    optax.adam(\n",
    "    learning_rate=Learn_Rate, \n",
    "    b1=beta_1, \n",
    "    b2=beta_2\n",
    "    )\n",
    ")\n",
    "\n",
    "def loss_fn(graph_batch, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(graph_batch, Dataset_parameters)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean(optax.huber_loss(prediction_e_prime, target_e_prime))\n",
    "\n",
    "    mean_e = Dataset_parameters['target_e']['mean']\n",
    "    std_dev_e = Dataset_parameters['target_e']['std_dev']\n",
    "    target_zero = (0 - mean_e) / std_dev_e\n",
    "    \n",
    "    zero_graph = jraph.graphstuple(\n",
    "        \n",
    "    )\n",
    "    prediction_zero, _ = Model(zero_graph, Dataset_parameters)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8161a58",
   "metadata": {},
   "source": [
    "Batch Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_and_split_dataset(graphs, batch_size, train_split, CV_split, test_split, key):\n",
    "    shuffled_graphs_index = jax.random.permutation(key, len(graphs))\n",
    "    n_train_batches = (train_split * len(graphs)) // batch_size\n",
    "    n_test_batches = (test_split * len(graphs)) // batch_size\n",
    "    n_CV_batches = (CV_split * len(graphs)) // batch_size\n",
    "\n",
    "    train_batches_i = shuffled_graphs_index[:n_train_batches]\n",
    "    test_batches_i = shuffled_graphs_index[n_train_batches:(n_train_batches + n_test_batches)]\n",
    "    CV_batches_i = shuffled_graphs_index[(n_train_batches + n_test_batches):(n_train_batches + n_test_batches + n_CV_batches)]\n",
    "\n",
    "    train_batches = graphs[train_batches_i]\n",
    "    test_batches = graphs[test_batches_i]\n",
    "    CV_batches = graphs[CV_batches_i]\n",
    "    return train_batches, CV_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b98a1b",
   "metadata": {},
   "source": [
    "Batching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a344e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd37a6b",
   "metadata": {},
   "source": [
    "Training Dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any\n",
    "    state: Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db7c5",
   "metadata": {},
   "source": [
    "CV loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_loss_fn(CV_batches, graph_def, params, state, dataset_parameters, alpha, gamma, lambda_):\n",
    "    Model = nnx.merge(graph_def, params, state)\n",
    "    CV_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for CV_batch in CV_batches:\n",
    "        batch_count += 1\n",
    "        graph_batch = CV_batch[]\n",
    "        target_e = CV_batch[]\n",
    "        target_e_prime = CV_batch[]\n",
    "\n",
    "        loss = loss_fn(\n",
    "            graph_batch,\n",
    "            target_e,\n",
    "            target_e_prime,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        CV_loss += loss\n",
    "\n",
    "    CV_loss = CV_loss / batch_count\n",
    "\n",
    "    return CV_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24c632",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(params, graph_def, state, opt_state, GraphandTarget_batch, *, dataset_parameters, alpha, gamma, lambda_):\n",
    "\n",
    "    target_e = GraphandTarget_batch['target_e']\n",
    "    target_e_prime = GraphandTarget_batch['target_e_prime']\n",
    "    graph_batch = GraphandTarget_batch['graphs']\n",
    "\n",
    "    def wrapped_loss(params_, state_):\n",
    "        Model = nnx.merge(graph_def, params_, state_)\n",
    "        loss = loss_fn(\n",
    "            graph_batch,\n",
    "            target_e,\n",
    "            target_e_prime,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "    \n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss, argnums=0)(params, state)\n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "    \n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98768043",
   "metadata": {},
   "source": [
    "Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59280fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1], \n",
    "    dim_hidden1_in=512,\n",
    "    dim_hidden2_in=256, \n",
    "    dim_hidden3_in=128,\n",
    "    dim_hidden4_in=64,\n",
    "    dim_hidden5_in=32,\n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    for batch in tqdm(train_batches, desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "\n",
    "        new_params, new_state, new_opt_state, batch_loss = train_step(\n",
    "\n",
    "        )\n",
    "\n",
    "        CV_loss = CV_loss_fn(\n",
    "            CV_batches,\n",
    "            graph_def,\n",
    "            new_params,\n",
    "            new_state,\n",
    "            dataset_parameters,\n",
    "            alpha,\n",
    "            gamma,\n",
    "            lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293e5bf",
   "metadata": {},
   "source": [
    "Trained Model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1815d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class Model_storage(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any\n",
    "    states: Any"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
