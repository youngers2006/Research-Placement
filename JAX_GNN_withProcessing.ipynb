{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "import flax.nnx as nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "import jraph\n",
    "from itertools import combinations\n",
    "import meshio\n",
    "import numpy as np\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f78afd1",
   "metadata": {},
   "source": [
    "Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b53ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 50\n",
    "alpha = 1.0 ; gamma = 1.0 ; lambda_ = 1.0\n",
    "beta_1 = 0.9 ; beta_2 = 0.999\n",
    "batch_size = 10 \n",
    "train_split = 0.8 ; CV_split = 0.1 ; test_split = 0.1\n",
    "Learn_Rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd846b",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f457fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992108e",
   "metadata": {},
   "source": [
    "Graph gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3203f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_known(boundary_points, points):\n",
    "    is_known = jnp.zeros(points.shape[0]) \n",
    "    is_known = is_known.at[boundary_points].set(1)\n",
    "    return is_known\n",
    "\n",
    "def build_send_receive(cell):\n",
    "    sender_array = []\n",
    "    receiver_array = []\n",
    "    for edge in combinations(cell,2):\n",
    "        sender_array.append(edge[0])\n",
    "        receiver_array.append(edge[1])\n",
    "    return sender_array, receiver_array\n",
    "\n",
    "def build_graphs(senders, receivers, positions, boundary_points, U) -> jraph.GraphsTuple:\n",
    "    is_known = Get_known(boundary_points, positions)\n",
    "    U_applied = jnp.zeros_like(U).at[boundary_points].set(U[boundary_points])\n",
    "        \n",
    "    node_features = jnp.concatenate([positions, U_applied, jnp.expand_dims(is_known, axis=1)], axis=1)\n",
    "    num_nodes = positions.shape[0]\n",
    "\n",
    "    graph = jraph.GraphsTuple(\n",
    "        nodes=node_features,\n",
    "        senders=senders,\n",
    "        receivers=receivers,\n",
    "        edges=None,\n",
    "        globals=None, \n",
    "        n_node=jnp.array([num_nodes]),\n",
    "        n_edge=jnp.array([len(senders)])\n",
    "    )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab417de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete.\n",
      "\n",
      "Positions array shape: (1331, 3)\n",
      "Boundary indices array shape: (602,)\n",
      "Senders array shape: (14230,)\n",
      "Receivers array shape: (14230,)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601]\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your result file\n",
    "filepath = os.path.join('data', 'vtk', 'u_final.vtu')\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    print(f\"Error: '{filepath}' not found. Please check the file path.\")\n",
    "else:\n",
    "    mesh = meshio.read(filepath)\n",
    "\n",
    "    positions = mesh.points\n",
    "    right_face_indices = np.where(np.isclose(positions[:, 0], 1.0))[0]\n",
    "    element_connectivity = mesh.cells[0].data\n",
    "\n",
    "    unique_edges = set()\n",
    "\n",
    "    for element in element_connectivity:\n",
    "        element_senders, element_receivers = build_send_receive(element)\n",
    "        \n",
    "        for i in range(len(element_senders)):\n",
    "            edge = tuple(sorted((element_senders[i], element_receivers[i])))\n",
    "            unique_edges.add(edge)\n",
    "\n",
    "    edge_list = jnp.array(list(unique_edges))\n",
    "    senders = edge_list[:, 0]\n",
    "    receivers = edge_list[:, 1]\n",
    "\n",
    "    on_face_x0 = np.isclose(positions[:, 0], 0.0)\n",
    "    on_face_x1 = np.isclose(positions[:, 0], 1.0)\n",
    "    on_face_y0 = np.isclose(positions[:, 1], 0.0)\n",
    "    on_face_y1 = np.isclose(positions[:, 1], 1.0)\n",
    "    on_face_z0 = np.isclose(positions[:, 2], 0.0)\n",
    "    on_face_z1 = np.isclose(positions[:, 2], 1.0)\n",
    "\n",
    "    is_on_any_face = (on_face_x0 | on_face_x1 |\n",
    "                      on_face_y0 | on_face_y1 |\n",
    "                      on_face_z0 | on_face_z1)\n",
    "\n",
    "    boundary_nodes_ = np.where(is_on_any_face)[0]\n",
    "\n",
    "    print(\"Data extraction complete.\\n\")\n",
    "    print(f\"Positions array shape: {positions.shape}\")\n",
    "    print(f\"Boundary indices array shape: {boundary_nodes_.shape}\")\n",
    "    print(f\"Senders array shape: {senders.shape}\")\n",
    "    print(f\"Receivers array shape: {receivers.shape}\")\n",
    "\n",
    "    print(boundary_nodes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e202054",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8994d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully unpickled data.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file = r\"/home/samuel/Github/Research-Placement/data/simulation_results.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(data_file, \"rb\") as f:\n",
    "        data_unpickled_1 = pickle.load(f)\n",
    "    print(f\"Successfully unpickled data.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {data_file}\")\n",
    "    dataset_list = {}\n",
    "\n",
    "dataset_dict = data_unpickled_1\n",
    "\n",
    "# Not tunable, is known from how many sims ran\n",
    "num_sims = 100\n",
    "# permutation list for batching\n",
    "index_list = jnp.arange(num_sims)\n",
    "permutated_index_list = jax.random.permutation(jax.random.PRNGKey(0), index_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183f4bc",
   "metadata": {},
   "source": [
    "Pre-processing functions - Need to be changed when preprocessing is implemented to accomodate the data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c6ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*, train_split, permutated_idxs):\n",
    "    permuted = jnp.array(data)[permutated_idxs]\n",
    "    split_idx = int(permutated_idxs.shape[0] * train_split)\n",
    "    train_data = permuted[:split_idx]\n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a8d00",
   "metadata": {},
   "source": [
    "Data pre-processing and graph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd47f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "boundary_nodes = jnp.array(list(dataset_dict[0]['boundary_strain_energy_gradient'].keys()), dtype=jnp.int32)\n",
    "processed_dataset_dict = dataset_dict\n",
    "\n",
    "graphs_list = []\n",
    "displacements_list = []\n",
    "target_e_list = []\n",
    "target_e_prime_list = []\n",
    "boundary_displacements_list = []\n",
    "\n",
    "num_nodes = positions.shape[0]\n",
    "\n",
    "for i in tqdm(range(num_sims), leave=False):\n",
    "    sim_entry = processed_dataset_dict[i]\n",
    "\n",
    "    U_full = jnp.array(sim_entry['full_displacement_vector']).reshape(num_nodes,3)\n",
    "    displacements_list.append(U_full)\n",
    "\n",
    "    disp_map = sim_entry['applied_boundary_displacements']\n",
    "    disp_vals = jnp.stack([jnp.array(disp_map[int(k)]) for k in boundary_nodes])  \n",
    "    boundary_displacements_list.append(disp_vals)\n",
    "\n",
    "    grad_map = sim_entry['boundary_strain_energy_gradient']\n",
    "    grad_vals = jnp.stack([jnp.array(grad_map[int(k)]) for k in boundary_nodes])  \n",
    "    target_e_prime_list.append(grad_vals)\n",
    "\n",
    "    target_e = jnp.array(sim_entry['strain_energy'])\n",
    "    target_e_list.append(target_e)\n",
    "\n",
    "    graph = build_graphs(\n",
    "        senders, \n",
    "        receivers, \n",
    "        positions, \n",
    "        boundary_nodes,\n",
    "        U_full\n",
    "    )\n",
    "    graphs_list.append(graph)\n",
    "\n",
    "displacements_list = jnp.stack(displacements_list, axis=0)\n",
    "boundary_displacements_list = jnp.stack(boundary_displacements_list, axis=0)\n",
    "target_e_list = jnp.stack(target_e_list, axis=0)\n",
    "target_e_prime_list = jnp.stack(target_e_prime_list, axis=0)\n",
    "\n",
    "displacement_params = mean_and_std_dev(boundary_displacements_list, train_split=train_split, permutated_idxs=permutated_index_list)\n",
    "bd_displacement_list_scaled = scale_data(boundary_displacements_list, data_params=displacement_params)\n",
    "\n",
    "e_params = mean_and_std_dev(target_e_list, train_split=train_split, permutated_idxs=permutated_index_list)\n",
    "target_e_list_scaled = scale_data(target_e_list, data_params=e_params)\n",
    "\n",
    "e_prime_params = mean_and_std_dev(target_e_prime_list, train_split=train_split, permutated_idxs=permutated_index_list)\n",
    "target_e_prime_list_scaled = scale_data(target_e_prime_list, data_params=e_prime_params)\n",
    "\n",
    "params_dict = {\n",
    "    'displacements': displacement_params,\n",
    "    'energy': e_params,\n",
    "    'grad': e_prime_params\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    'graphs_list': graphs_list,\n",
    "    'displacements': displacements_list,\n",
    "    'target_e': target_e_list_scaled,\n",
    "    'target_e_prime': target_e_prime_list_scaled,\n",
    "    'boundary_displacements': bd_displacement_list_scaled,\n",
    "    'boundary_nodes_indices': boundary_nodes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511eda85",
   "metadata": {},
   "source": [
    "Batching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "686d79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_and_split_dataset(dataset_dict, batch_size, train_split, CV_split, test_split, permutated_index_list):\n",
    "    total_samples = permutated_index_list.shape[0]\n",
    "    idx_train_samples = int(train_split * total_samples) \n",
    "    idx_test_samples = idx_train_samples + int(test_split * total_samples) \n",
    "\n",
    "    train_idx = list(permutated_index_list[:idx_train_samples])\n",
    "    test_idx = list(permutated_index_list[idx_train_samples:idx_test_samples])\n",
    "    CV_idx = list(permutated_index_list[idx_test_samples:])\n",
    "\n",
    "    def batch_indices(idx):  \n",
    "        if not idx:\n",
    "            return\n",
    "        num_samples = len(idx)\n",
    "        num_batches = num_samples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            \n",
    "            graphs_in_batch = [dataset_dict['graphs_list'][i] for i in batch_idx]\n",
    "            displacements_batch = [dataset_dict['displacements'][i] for i in batch_idx]\n",
    "            e_batch = [dataset_dict['target_e'][i] for i in batch_idx]\n",
    "            e_prime_batch = [dataset_dict['target_e_prime'][i] for i in batch_idx]\n",
    "\n",
    "            batched_graphs = graphs_in_batch\n",
    "            batched_displacements = jnp.array(displacements_batch)\n",
    "            batched_e = jnp.array(e_batch)\n",
    "            batched_e_prime = jnp.array(e_prime_batch)\n",
    "\n",
    "            yield {\n",
    "                'graphs': batched_graphs, \n",
    "                'displacements': batched_displacements, \n",
    "                'target_e': batched_e, \n",
    "                'target_e_prime': batched_e_prime\n",
    "            }\n",
    "    \n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    CV_batches = list(batch_indices(CV_idx))\n",
    "\n",
    "    return train_batches, CV_batches, test_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9a939",
   "metadata": {},
   "source": [
    "Batching graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b07a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, CV_batches, test_batches = batch_and_split_dataset(\n",
    "    dataset, \n",
    "    batch_size, \n",
    "    train_split, \n",
    "    CV_split, \n",
    "    test_split, \n",
    "    permutated_index_list\n",
    ")\n",
    "\n",
    "is_known_zero = Get_known(boundary_nodes, positions)\n",
    "is_known_zero_expanded = jnp.expand_dims(is_known_zero, axis=1)\n",
    "U_zero = jnp.zeros_like(positions)\n",
    "U_applied_zero = jnp.zeros_like(boundary_displacements_list[0])\n",
    "U_applied_zero = scale_data(U_applied_zero, data_params=displacement_params)\n",
    "U_zero = jnp.at[boundary_nodes].set(U_applied_zero)\n",
    "node_features_zero = jnp.concatenate([positions, U_zero, is_known_zero_expanded], axis=1)\n",
    "\n",
    "zero_graph = jraph.GraphsTuple(\n",
    "    nodes=node_features_zero,\n",
    "    senders=senders,\n",
    "    receivers=receivers,\n",
    "    edges=None,\n",
    "    globals=None, \n",
    "    n_node=jnp.array([positions.shape[0]]),\n",
    "    n_edge=jnp.array([len(senders)])\n",
    ")\n",
    "\n",
    "zero_list = [zero_graph for _ in range(batch_size)]\n",
    "batched_zero_graph = zero_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615042f",
   "metadata": {},
   "source": [
    "GAT Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1030d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GATEdges:\n",
    "    score: jax.Array\n",
    "    message: jax.Array\n",
    "\n",
    "class GAT(nnx.Module):\n",
    "    def __init__(self, in_features, out_features, *, rngs):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.GNN = jraph.GraphNetwork(\n",
    "            update_edge_fn=self.update_edge_fn,\n",
    "            update_node_fn=self.update_node_fn,\n",
    "            aggregate_edges_for_nodes_fn=self.aggregate_edges_for_nodes_fn\n",
    "        )\n",
    "\n",
    "        initialiser = nnx.initializers.lecun_normal()\n",
    "        self.Weight_mat = nnx.Param(initialiser(rngs.params(), (in_features, out_features)))\n",
    "        self.Attention_mat = nnx.Param(initialiser(rngs.params(), (2 * out_features, 1)))\n",
    "\n",
    "    def update_edge_fn(self, edges, senders, receivers, globals_):\n",
    "        \"computes edge features and outputs a dict containing the edge features\"\n",
    "        h_sender = senders @ self.Weight_mat\n",
    "        h_reciever = receivers @ self.Weight_mat\n",
    "\n",
    "        send_recieve_features = jnp.concatenate([h_sender, h_reciever], axis=-1)\n",
    "        attention_scores = nnx.leaky_relu(send_recieve_features @ self.Attention_mat)\n",
    "\n",
    "        return GATEdges(score=attention_scores, message=h_sender)\n",
    "    \n",
    "    def aggregate_edges_for_nodes_fn(self, edges: GATEdges, segment_ids, num_segments) -> jax.Array:\n",
    "        \"aggregates all edge messages for a node and outputs the aggregated messages\"\n",
    "        attention_coeffs = jraph.segment_softmax(\n",
    "            logits=edges.score,\n",
    "            segment_ids=segment_ids,\n",
    "            num_segments=num_segments\n",
    "        )\n",
    "\n",
    "        weighted_messages = edges.message * attention_coeffs\n",
    "\n",
    "        aggregated_messages = jraph.segment_sum(\n",
    "            data=weighted_messages,\n",
    "            segment_ids=segment_ids, \n",
    "            num_segments=num_segments\n",
    "        )\n",
    "\n",
    "        return aggregated_messages\n",
    "\n",
    "    def update_node_fn(self, nodes, sent_edges, received_edges, globals_):\n",
    "        \"takes aggregated node messages and applies them to the graph\"\n",
    "        return received_edges\n",
    "\n",
    "    def __call__(self, graph):\n",
    "        return self.GNN(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045c04d",
   "metadata": {},
   "source": [
    "Block Coarsening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a377c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockCoursening(nnx.Module): \n",
    "    def __init__(self, block_size: tuple[int, int, int], max_coarsened_edges=10000, *, rngs: nnx.Rngs):\n",
    "        self.block_dims = tuple(int(x) for x in block_size)\n",
    "        self.num_blocks = int(self.block_dims[0] * self.block_dims[1] * self.block_dims[2])\n",
    "\n",
    "    def partition(self, node_coords):\n",
    "        dims_arr = jnp.array(self.block_dims)\n",
    "        min_coords = jnp.min(node_coords, axis=0)\n",
    "        max_coords = jnp.max(node_coords, axis=0)\n",
    "        grid_cell_size = (max_coords - min_coords) / dims_arr\n",
    "        relative_coords = node_coords - min_coords\n",
    "\n",
    "        normalized_coords = relative_coords / grid_cell_size\n",
    "        grid_indices = jnp.floor(normalized_coords).astype(jnp.int32)\n",
    "        grid_indices = jnp.clip(grid_indices, 0, dims_arr - 1)\n",
    "    \n",
    "        block_ids = (\n",
    "                grid_indices[:, 0] * (self.block_dims[1] * self.block_dims[2]) + \n",
    "                grid_indices[:, 1] * self.block_dims[2] + grid_indices[:, 2]\n",
    "        )\n",
    "        return block_ids\n",
    "    \n",
    "    def __call__(self, graph: jraph.GraphsTuple, node_coords: jax.Array):\n",
    "        block_ids = self.partition(node_coords)\n",
    "        num_blocks = self.num_blocks\n",
    "\n",
    "        coarsened_nodes = jraph.segment_sum(\n",
    "            data=graph.nodes,\n",
    "            segment_ids=block_ids,\n",
    "            num_segments=num_blocks\n",
    "        )\n",
    "\n",
    "        sizes = jraph.segment_sum(\n",
    "            jnp.ones((graph.nodes.shape[0],1)), \n",
    "            block_ids, \n",
    "            num_blocks\n",
    "        )          \n",
    "        coarsened_nodes = coarsened_nodes / jnp.sqrt(sizes + 1e-10)\n",
    "\n",
    "        block_senders = block_ids[graph.senders]\n",
    "        block_receivers = block_ids[graph.receivers]\n",
    "\n",
    "        not_self = block_senders != block_receivers\n",
    "\n",
    "        keys = block_senders * num_blocks + block_receivers\n",
    "        idx = jnp.arange(keys.shape[0])\n",
    "        sorted_keys, perm = jax.lax.sort_key_val(keys, idx)  \n",
    "    \n",
    "        sentinel = jnp.array([-1], dtype=sorted_keys.dtype)\n",
    "        prev = jnp.concatenate([sentinel, sorted_keys[:-1]])\n",
    "        unique_sorted = sorted_keys != prev\n",
    "\n",
    "        unique_mask = jnp.zeros_like(unique_sorted)\n",
    "        unique_mask = unique_mask.at[perm].set(unique_sorted)\n",
    "\n",
    "        final_mask = (unique_mask & not_self).astype(jnp.float32)  \n",
    "        edge_weights = final_mask[:, None]\n",
    "\n",
    "        pooled_graph = jraph.GraphsTuple(\n",
    "            nodes=coarsened_nodes,\n",
    "            edges=edge_weights,\n",
    "            senders=block_senders,\n",
    "            receivers=block_receivers,\n",
    "            n_edge=jnp.array([edge_weights.shape[0]]),\n",
    "            n_node=jnp.array([num_blocks]),\n",
    "            globals=None\n",
    "        )\n",
    "        return pooled_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ec029",
   "metadata": {},
   "source": [
    "Graph_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNorm(nnx.Module):\n",
    "    def __init__(self, dim: int, *, eps: float = 1e-10, rngs: nnx.Rngs):\n",
    "        self.eps = eps\n",
    "        self.gamma = nnx.Param(jnp.ones((dim,), dtype=jnp.float32))\n",
    "        self.beta = nnx.Param(jnp.zeros((dim,), dtype=jnp.float32))\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        mean = jnp.mean(x, axis=0, keepdims=True)\n",
    "        var = jnp.var(x, axis=0, keepdims=True)\n",
    "        x_hat = (x - mean) / jnp.sqrt(var + self.eps)\n",
    "        return self.gamma * x_hat + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314af953",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95b1149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nnx.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            node_feature_dim: int, \n",
    "            embedding_dim: int, \n",
    "            output_dim: int, \n",
    "            pooling_block_dims_1,  \n",
    "            boundary_nodes, \n",
    "            disp_mean,\n",
    "            disp_std,\n",
    "            e_mean,\n",
    "            e_std,\n",
    "            grad_mean, \n",
    "            grad_std,\n",
    "            rngs: nnx.Rngs\n",
    "        ):\n",
    "\n",
    "        self.embedding_layer = nnx.Linear(node_feature_dim, embedding_dim, rngs=rngs)\n",
    "        self.encoderL1 = GAT(embedding_dim, embedding_dim, rngs=rngs)\n",
    "        self.graphNormL1 = GraphNorm(embedding_dim, eps=1e-5, rngs=rngs)\n",
    "        self.encoderL2 = GAT(embedding_dim, embedding_dim, rngs=rngs)\n",
    "        self.graphNormL2 = GraphNorm(embedding_dim, eps=1e-5, rngs=rngs)\n",
    "        self.encoderL3 = GAT(embedding_dim, embedding_dim, rngs=rngs)\n",
    "        self.decoding_layer = nnx.Linear(embedding_dim, output_dim, rngs=rngs)\n",
    "\n",
    "        self.poolingLayer1 = BlockCoursening(pooling_block_dims_1, rngs=rngs)\n",
    "\n",
    "        self.boundary_nodes = jnp.array(boundary_nodes, dtype=jnp.int32)\n",
    "\n",
    "        self.disp_mean = disp_mean ; self.disp_std = disp_std\n",
    "        self.e_mean = e_mean ; self.e_std = e_std\n",
    "        self.grad_mean = grad_mean ; self.grad_std = grad_std\n",
    "\n",
    "    def embedder(self, graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "        \"\"\"Maps current node features to higher dimensional node embeddings\"\"\"\n",
    "        nodes = graph.nodes\n",
    "        pos = nodes[:, 0:3]\n",
    "        disp = nodes[:, 3:6]\n",
    "        flag = nodes[:, 6:]\n",
    "\n",
    "        disp_norm = disp\n",
    "        b_disp = disp[self.boundary_nodes]\n",
    "        b_disp_norm = (b_disp - self.disp_mean) / self.disp_std\n",
    "        disp_norm = disp_norm.at[self.boundary_nodes].set(b_disp_norm)\n",
    "        \n",
    "        nodes_scaled = jnp.concatenate([pos, disp_norm, flag], axis=1)\n",
    "        embeddings = self.embedding_layer(nodes_scaled)\n",
    "        return graph._replace(nodes=embeddings)\n",
    "    \n",
    "    def apply_activation_and_res(self, graph: jraph.GraphsTuple, residual: jax.Array) -> jraph.GraphsTuple:\n",
    "        \"\"\"Applies activation function and residual to the graph\"\"\"\n",
    "        activated_nodes = nnx.silu(graph.nodes) + residual\n",
    "        return graph._replace(nodes=activated_nodes)\n",
    "    \n",
    "    def apply_res(self, graph: jraph.GraphsTuple, residual: jax.Array) -> jraph.GraphsTuple:\n",
    "        \"\"\"Applies activation_function to the graph\"\"\"\n",
    "        new_nodes = graph.nodes + residual\n",
    "        return graph._replace(nodes=new_nodes)\n",
    "        \n",
    "    def decoder(self, graph: jraph.GraphsTuple) -> jax.Array: \n",
    "        \"\"\"Takes processed graph and aggregates nodes then passes them through the decoding layer to predict energy\"\"\"\n",
    "        num_nodes = graph.nodes.shape[0]\n",
    "        node_graph_indices = jnp.zeros(num_nodes, dtype=jnp.int32)\n",
    "        aggregate_nodes = jraph.segment_sum(\n",
    "            data=graph.nodes, \n",
    "            segment_ids=node_graph_indices,\n",
    "            num_segments=1\n",
    "        )\n",
    "        out = self.decoding_layer(aggregate_nodes)\n",
    "        return out.squeeze()\n",
    "        \n",
    "    def forward_pass(self, G: jraph.GraphsTuple) -> jax.Array:\n",
    "        \"\"\"Takes a graph and passes it through the GNN to predict energy\"\"\"\n",
    "        node_coords = G.nodes[:, 0:3]\n",
    "        G = self.embedder(G)\n",
    "        res1 = G.nodes\n",
    "\n",
    "        G = self.encoderL1(G)\n",
    "        nodes_norm = self.graphNormL1(G.nodes)\n",
    "        G = G._replace(nodes=nodes_norm)\n",
    "        G = self.apply_activation_and_res(G, res1)\n",
    "        G = self.poolingLayer1(G, node_coords)\n",
    "        res2 = G.nodes\n",
    "\n",
    "        G = self.encoderL2(G)\n",
    "        nodes_norm = self.graphNormL2(G.nodes)\n",
    "        G = G._replace(nodes=nodes_norm)\n",
    "        G = self.apply_activation_and_res(G, res2)\n",
    "        res3 = G.nodes\n",
    "\n",
    "        G = self.encoderL3(G)\n",
    "        G = self.apply_res(G, res3)\n",
    "\n",
    "        e = self.decoder(G)\n",
    "        return e\n",
    "    \n",
    "    def call_single(self, G: jraph.GraphsTuple):\n",
    "        \"\"\"Call the GNN for a single graph\"\"\"\n",
    "        e = self.forward_pass(G)\n",
    "\n",
    "        def energy_fn(nodes):\n",
    "            G_temp = G._replace(nodes=nodes)\n",
    "            result = self.forward_pass(G_temp)\n",
    "            return result.squeeze()\n",
    "\n",
    "        grad_fn = jax.grad(energy_fn)\n",
    "        grads = grad_fn(G.nodes)\n",
    "        e_prime_raw_full = grads[:, 3:6]\n",
    "        e_prime_raw = e_prime_raw_full[self.boundary_nodes, :]\n",
    "\n",
    "        e_prime_physical = e_prime_raw * (self.e_std / self.disp_std)\n",
    "        e_prime = (e_prime_physical - self.grad_mean) / self.grad_std\n",
    "\n",
    "        return e, e_prime\n",
    "    \n",
    "    def __call__(self, graphs_list: list):\n",
    "        \"Main call method for handling batches of identically structured graphs\"\n",
    "    \n",
    "        base = graphs_list[0]\n",
    "        stacked_nodes = jnp.stack([g.nodes for g in graphs_list])\n",
    "\n",
    "        def per_sample(nodes_slice):\n",
    "            g = base._replace(nodes=nodes_slice)\n",
    "            return self.call_single(g)\n",
    "        \n",
    "        vmapped_call = jax.vmap(\n",
    "            per_sample,\n",
    "            in_axes=0\n",
    "        )\n",
    "        e_batch, e_prime_batch = vmapped_call(stacked_nodes)\n",
    "        return e_batch, e_prime_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9615288",
   "metadata": {},
   "source": [
    "Loss function and Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da4e759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(batch, batched_zero_graph,*, Model, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    target_e_batch = batch['target_e']\n",
    "    target_e_prime_batch = batch['target_e_prime']\n",
    "    graph_batch = batch['graphs']\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(graph_batch)\n",
    "    loss_e = jnp.mean((prediction_e - target_e_batch)**2)\n",
    "    loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime_batch)**2)\n",
    "    \n",
    "    prediction_zero, _ = Model(batched_zero_graph)\n",
    "    loss_zero = jnp.mean((prediction_zero - 0.0)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db7c5",
   "metadata": {},
   "source": [
    "CV loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1a6bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_loss_fn(CV_batches, batched_zero_graph, Model: GNN, alpha, gamma, lambda_):\n",
    "    CV_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for CV_batch in CV_batches:\n",
    "        batch_count += 1\n",
    "\n",
    "        loss = loss_fn(\n",
    "            CV_batch,\n",
    "            batched_zero_graph,\n",
    "            Model=Model,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        CV_loss += loss\n",
    "\n",
    "    if batch_count > 0:\n",
    "        ret = CV_loss / batch_count\n",
    "        return ret\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24c632",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d699c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(Model, optimiser, GraphandTarget_batch, batched_zero_graph, *, alpha, gamma, lambda_):\n",
    "\n",
    "    def wrapped_loss(Model):\n",
    "        loss = loss_fn(\n",
    "            GraphandTarget_batch,\n",
    "            batched_zero_graph,\n",
    "            Model=Model,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_ \n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss, argnums=0)(Model)\n",
    "    optimiser.update(Model, grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98768043",
   "metadata": {},
   "source": [
    "Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e59280fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "Model = GNN(\n",
    "    node_feature_dim=7, \n",
    "    embedding_dim=128,\n",
    "    output_dim=1,\n",
    "    pooling_block_dims_1=(5,5,5),\n",
    "    boundary_nodes=dataset['boundary_nodes_indices'],\n",
    "    disp_mean=params_dict['displacements']['mean'],\n",
    "    disp_std=params_dict['displacements']['std_dev'],\n",
    "    e_mean=params_dict['energy']['mean'],\n",
    "    e_std=params_dict['energy']['std_dev'],\n",
    "    grad_mean=params_dict['grad']['mean'], \n",
    "    grad_std=params_dict['grad']['std_dev'],\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "optimiser = nnx.Optimizer(\n",
    "    Model,\n",
    "    optax.adam(\n",
    "        learning_rate=Learn_Rate, \n",
    "        b1=beta_1, \n",
    "        b2=beta_2\n",
    "    ),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "loss_record = []\n",
    "CV_loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    for batch in tqdm(train_batches, desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        batch_loss = train_step(\n",
    "            Model,\n",
    "            optimiser,\n",
    "            batch,\n",
    "            batched_zero_graph,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lambda_=lambda_\n",
    "        )\n",
    "\n",
    "        batch_count += 1\n",
    "        running_loss += batch_loss\n",
    "\n",
    "    CV_loss = CV_loss_fn(\n",
    "        CV_batches,\n",
    "        batched_zero_graph,\n",
    "        Model,\n",
    "        alpha,\n",
    "        gamma,\n",
    "        lambda_\n",
    "    )\n",
    "    \n",
    "    avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)\n",
    "    CV_loss_record.append(CV_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402f7aa",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d65db5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x703a1c3f8e10>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_record[48:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_WSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
