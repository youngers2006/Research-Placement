{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4df718",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a381aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8c0ba",
   "metadata": {},
   "source": [
    "Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfed4d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Not Available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda\")\n",
    "    print(\"GPU Available\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"GPU Not Available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34591b1f",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2b08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Learn_Rate = 0.001\n",
    "beta1 = 0.999\n",
    "beta2 = 0.9\n",
    "Epochs = 1000000\n",
    "alpha = 1.0\n",
    "gamma = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e316a",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38fd097e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DataSetup'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m data_file = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msamue\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSimulation.pickle\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_file,\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     data_unpickled = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'DataSetup'"
     ]
    }
   ],
   "source": [
    "# Wating for Dataset, input will be 3x3 strain matricies (flattened to 9x1), and labels will be scalar energy values and a 3x3 energy derivative matrix (flattened to 9x1)\n",
    "import pickle\n",
    "\n",
    "data_file = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "\n",
    "with open(data_file,\"rb\") as f:\n",
    "    data_unpickled = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985158bb",
   "metadata": {},
   "source": [
    "Network Architecture and Energy Gradient Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_input_dims = 9\n",
    "energy_dims = 1\n",
    "\n",
    "class Energy_Net(nn.module):\n",
    "    def __init__(self, strain_input_dims, energy_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Layer1 = nn.Linear(strain_input_dims,1024)\n",
    "        self.Layer2 = nn.Linear(1024,512)\n",
    "        self.Layer3 = nn.Linear(512,128)\n",
    "        self.Layer4 = nn.Linear(128,32)\n",
    "        self.Layer5 = nn.Linear(32,energy_dims)\n",
    "\n",
    "        self.silu = nn.SiLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        if not x.requires_grad:\n",
    "            x.requires_grad_(True)\n",
    "\n",
    "        x = self.Layer1(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.Layer2(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.Layer3(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.Layer4(x)\n",
    "        x = self.silu(x)\n",
    "        energy = self.Layer5(x)\n",
    "\n",
    "        energy_derivatives = torch.autograd.grad(\n",
    "            outputs=energy,\n",
    "            inputs=x,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return energy, energy_derivatives\n",
    "\n",
    "Model = Energy_Net(strain_input_dims, energy_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94885ba7",
   "metadata": {},
   "source": [
    "Optimiser and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2000a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.Adam(Model.parameters(),lr = Learn_Rate,betas=(beta1, beta2))\n",
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a609e",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = 0\n",
    "loss_record = []\n",
    "\n",
    "for epoch in Epochs:\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        input_batch, target_energy_batch, target_energy_Deriv_batch = batch # Correct this to get the actual values\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        energy_pred, energy_deriv_pred = Model(input_batch)\n",
    "\n",
    "        loss_E = loss(energy_pred,target_energy_batch)\n",
    "\n",
    "        loss_E_Deriv = loss(energy_deriv_pred,target_energy_Deriv_batch)\n",
    "\n",
    "        loss_total = alpha * loss_E + gamma * loss_E_Deriv\n",
    "\n",
    "        loss_total.backward()\n",
    "\n",
    "        optimiser.step()\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(f\"Loss became NaN at batch {i} in epoch {epoch}!\")\n",
    "            if torch.isnan(Model.Layer1.weight).any():\n",
    "                print(\"Model weights have been corrupted by NaN values.\")\n",
    "            break\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    loss_record.append(running_loss)   \n",
    "\n",
    "# Plot Loss Across Training \n",
    "plt.plot(loss_record)\n",
    "print(f\"final loss after {Epochs} epcohs is {loss_record[len(loss_record)-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded59d5b",
   "metadata": {},
   "source": [
    "Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = 0 # correct this to be a test set not the training set\n",
    "energy_rmse = 0\n",
    "energy_deriv_rmse = 0\n",
    "loss_record_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for databatch in tqdm(dataloader,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "\n",
    "        input, energy_target, energy_deriv_target = databatch\n",
    "\n",
    "        energy_pred, energy_deriv_pred = Model(input)\n",
    "\n",
    "        loss_E = loss(energy_pred,target_energy_batch)\n",
    "\n",
    "        loss_E_Deriv = loss(energy_deriv_pred,target_energy_Deriv_batch)\n",
    "\n",
    "        loss_total = alpha * loss_E + gamma * loss_E_Deriv\n",
    "\n",
    "        energy_rmse_batch = torch.sqrt(torch.mean((energy_pred - energy_target) ** 2))\n",
    "        energy_deriv_rmse_batch = torch.sqrt(torch.mean((energy_deriv_pred - energy_deriv_target) ** 2))\n",
    "\n",
    "        energy_rmse += energy_rmse_batch\n",
    "        energy_deriv_rmse += energy_deriv_rmse_batch\n",
    "\n",
    "        loss_record_test.append(loss_total)\n",
    "\n",
    "energy_rmse_mean = energy_rmse/len(energy_rmse)\n",
    "energy_deriv_rmse_mean = energy_deriv_rmse/len(energy_deriv_rmse)\n",
    "\n",
    "print(energy_rmse_mean, \"/n\",energy_deriv_rmse_mean)\n",
    "\n",
    "plt.plot(loss_record_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
