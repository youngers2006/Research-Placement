{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2340, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(12340, 152, 3)\n",
      "(12340, 1)\n",
      "(12340, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)[0:2340]\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)[0:2340]\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)[0:2340]\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080cf8e",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa714ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 2000\n",
    "alpha = 1.0\n",
    "gamma = 200.0\n",
    "lambda_ = 20.0\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 40\n",
    "train_split = 0.9\n",
    "steps_per_epoch = input_dataset.shape[0] // Batch_size\n",
    "Learn_Rate = optax.exponential_decay(\n",
    "    init_value=0.001,\n",
    "    transition_steps=steps_per_epoch * 5,\n",
    "    decay_rate=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = jnp.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec14bee",
   "metadata": {},
   "source": [
    "Pre and post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6607d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data = data[:split_idx]\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "\n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']\n",
    "\n",
    "def add_square_feature(data,*,axis, feature_number):\n",
    "    new_feature = jnp.square(data)\n",
    "    new_data = jnp.concatenate([data,new_feature],axis=axis)\n",
    "    feature_number += 1\n",
    "    return new_data, feature_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset - Note: need to remove input scaling in the dataset as its done in the model, need to add a parameter calulator for the input that concatenates the square data then gets params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4221141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING RAW DATASET\n",
      "Key: 'displacements'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 912)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340,)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e_prime'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 456)\n",
      "  - Dtype: float32\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "input_dataset = input_dataset.reshape((input_dataset.shape[0],456))\n",
    "displacement_dim = input_dataset.shape[1]\n",
    "\n",
    "# add features\n",
    "num_features = 0\n",
    "input_dataset, num_features = add_square_feature(input_dataset,axis=1, feature_number=num_features)\n",
    "\n",
    "target_e_dataset = target_e_dataset.reshape((target_e_dataset.shape[0],))\n",
    "target_e_prime_dataset = target_e_prime_dataset.reshape((target_e_prime_dataset.shape[0],456))\n",
    "\n",
    "params_dict_displacement = mean_and_std_dev(input_dataset,train_split=train_split)\n",
    "params_dict_target_e = mean_and_std_dev(target_e_dataset,train_split=train_split)\n",
    "params_dict_target_e_prime = mean_and_std_dev(target_e_prime_dataset,train_split=train_split)\n",
    "\n",
    "input_dataset_scaled = scale_data(input_dataset,data_params=params_dict_displacement)\n",
    "target_e_dataset_scaled = scale_data(target_e_dataset, data_params=params_dict_target_e)\n",
    "target_e_prime_dataset_scaled = scale_data(target_e_prime_dataset, data_params=params_dict_target_e_prime)\n",
    "\n",
    "Dataset_parameters = {\n",
    "    'displacements':params_dict_displacement,\n",
    "    'target_e':params_dict_target_e,\n",
    "    'target_e_prime':params_dict_target_e_prime,\n",
    "    'num_features':num_features,\n",
    "    'standard_displacement_dim':displacement_dim\n",
    "}\n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset_scaled, \n",
    "    'target_e':target_e_dataset_scaled,\n",
    "    'target_e_prime':target_e_prime_dataset_scaled\n",
    "}\n",
    "\n",
    "print(\"INSPECTING RAW DATASET\")\n",
    "for key, value in Dataset.items():\n",
    "    print(f\"Key: '{key}'\")\n",
    "    print(f\"  - Type: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  - Shape: {value.shape}\")\n",
    "    else:\n",
    "        print(\"  - No shape attribute.\")\n",
    "    if hasattr(value, 'dtype'):\n",
    "        print(f\"  - Dtype: {value.dtype}\")\n",
    "print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b799cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1932328\n",
      "2.932326\n",
      "4.1916647\n"
     ]
    }
   ],
   "source": [
    "print(Dataset['displacements'][0][1])\n",
    "print(Dataset['target_e'][0])\n",
    "print(Dataset['target_e_prime'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.Module):\n",
    "    \"\"\"\n",
    "    Model architecture\n",
    "    Inputs: standardised displacements and all engineered features and the parameters of the dataset\n",
    "    Outputs: standardised energy value and standardised energy derivatives wrt each of the displacements\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int, dim_hidden3_in: int, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in,rngs=rngs)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in,rngs=rngs)\n",
    "        self.layer3 = Linear(din=dim_hidden2_in,dout=dim_hidden3_in,rngs=rngs)\n",
    "        self.output_layer = Linear(din=dim_hidden3_in,dout=dim_out,rngs=rngs)\n",
    "        self.silu = SiLU\n",
    "\n",
    "        self.projection1 = Linear(din=dim_hidden1_in, dout=dim_hidden2_in, rngs=rngs)\n",
    "        self.projection2 = Linear(din=dim_hidden2_in, dout=dim_hidden3_in, rngs=rngs)\n",
    "\n",
    "    def forwardPass(self,x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x_residual = x\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = x + self.projection1(x_residual)\n",
    "            x_residual = x\n",
    "            x = self.layer3(x)\n",
    "            x = self.silu(x)\n",
    "            x = x + self.projection2(x_residual)\n",
    "            x = self.output_layer(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "    def __call__(self,x_in,dataset_params):\n",
    "        \n",
    "        e = jax.vmap(self.forwardPass)(x_in)\n",
    "        dedx = jax.vmap(jax.grad(self.forwardPass))\n",
    "        e_prime_raw = dedx(x_in)\n",
    "        e_prime_raw_lin_ft = e_prime_raw[:, :456]\n",
    "\n",
    "        sigma_e = dataset_params['target_e']['std_dev']\n",
    "        sigma_x = dataset_params['displacements']['std_dev']\n",
    "        sigma_x_linear = sigma_x[:456]\n",
    "        mean_e_prime = dataset_params['target_e_prime']['mean']\n",
    "        sigma_e_prime = dataset_params['target_e_prime']['std_dev']\n",
    "\n",
    "        e_prime_physical = e_prime_raw_lin_ft * (sigma_e/sigma_x_linear)\n",
    "        e_prime = (e_prime_physical - mean_e_prime) / sigma_e_prime\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.chain(\n",
    "    optax.add_decayed_weights(weight_decay=1e-5),\n",
    "    optax.adam(\n",
    "    learning_rate=Learn_Rate, \n",
    "    b1=beta_1, \n",
    "    b2=beta_2\n",
    "    )\n",
    ")\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(x, Dataset_parameters)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean(optax.huber_loss(prediction_e_prime, target_e_prime))\n",
    "\n",
    "    mean_e = Dataset_parameters['target_e']['mean']\n",
    "    std_dev_e = Dataset_parameters['target_e']['std_dev']\n",
    "    target_zero = (0 - mean_e) / std_dev_e\n",
    "    \n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "    prediction_zero, _ = Model(x_zero, Dataset_parameters)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any \n",
    "    state: Any\n",
    "    alpha: float \n",
    "    gamma: float \n",
    "    lambda_: float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(params,state,opt_state,batch,*,graph_def,Dataset_parameters,alpha,gamma,lambda_):\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(params_,state_):\n",
    "        Model = nnx.merge(graph_def,params_,state_)\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=0)(params, state) \n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "\n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e88cb1",
   "metadata": {},
   "source": [
    "Batch Creator and test set creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9981b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_batch_dataset(dataset, batch_size, test_split=0.2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets, then yields batches for each.\n",
    "    Returns: (train_batches, test_batches).\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    split_idx = int(N * (1 - test_split))\n",
    "    train_idx = indices[:split_idx]\n",
    "    test_idx = indices[split_idx:]\n",
    "\n",
    "    def batch_indices(idx):\n",
    "        batch_num = len(idx) // batch_size\n",
    "        for i in range(batch_num):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            batch = {key: value[batch_idx] for key, value in dataset.items()}\n",
    "            yield batch\n",
    "\n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e467e7e",
   "metadata": {},
   "source": [
    "Create test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df10eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = split_and_batch_dataset(\n",
    "    Dataset, \n",
    "    Batch_size, \n",
    "    test_split=(1 - train_split), \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/2000:  76%|███████▌  | 210/277 [00:01<00:00, 123.42it/s]"
     ]
    }
   ],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1], \n",
    "    dim_hidden1_in=512,\n",
    "    dim_hidden2_in=256, \n",
    "    dim_hidden3_in=128,\n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    lambda_=lambda_\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(train_batches,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        \n",
    "        new_params, new_state, new_opt_state, loss_batch = training_step(\n",
    "            train_state.params,\n",
    "            train_state.state,\n",
    "            opt_state,\n",
    "            batch,\n",
    "            graph_def=train_state.graph_def,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=train_state.alpha,\n",
    "            gamma=train_state.gamma,\n",
    "            lambda_=train_state.lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e850b4",
   "metadata": {},
   "source": [
    "Final model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0738a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class ModelData(nnx.Object):\n",
    "    graph_def: Any\n",
    "    params: Any\n",
    "    state: Any\n",
    "    Dataset_parameters: Any\n",
    "    trained: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b354",
   "metadata": {},
   "source": [
    "Create Final model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78303138",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_trained = train_state.graph_def\n",
    "params_trained = train_state.params\n",
    "state_trained = train_state.state\n",
    "\n",
    "model_data = ModelData(\n",
    "    graph_def=graph_def_trained,\n",
    "    params=params_trained,\n",
    "    state=state_trained,\n",
    "    Dataset_parameters=Dataset_parameters,\n",
    "    trained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f93141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef96d48550>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.log10(jnp.array(loss_record)))\n",
    "#plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61baeb33",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_abs_error(pred,target):\n",
    "    n1 = pred.shape[0]\n",
    "    n2 = target.shape[0]\n",
    "\n",
    "    if n1 != n2:\n",
    "        raise(\"Error: inputs must have matching shape\")\n",
    "    \n",
    "    return (jnp.sum(jnp.abs(pred - target)) / n1)\n",
    "\n",
    "def test_model(model_data, test_batches,*,loss_fn, alpha, gamma, lambda_):\n",
    "\n",
    "    trained = model_data.trained\n",
    "    if not trained:\n",
    "        raise TypeError(\"Model is untrained, please train the model before evaluation\")\n",
    "\n",
    "    test_graph_def = model_data.graph_def\n",
    "    test_params = model_data.params\n",
    "    test_state = model_data.state\n",
    "\n",
    "    test_model = nnx.merge(test_graph_def,test_params,test_state)\n",
    "\n",
    "    loss_test = 0.0\n",
    "    test_count = 0\n",
    "\n",
    "    for batch in test_batches:\n",
    "        displacements_test = batch['displacements']\n",
    "        e_target_test = batch['target_e']\n",
    "        e_prime_target_test = batch['target_e_prime']\n",
    "\n",
    "        e_target_test_US = unscale_data(e_target_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_target_test_US = unscale_data(e_prime_target_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        e_pred_test, e_prime_pred_test = test_model(displacements_test,dataset_params=model_data.Dataset_parameters)\n",
    "\n",
    "        #displacements_test = unscale_data(displacements_test,data_params=Dataset_parameters['displacements'])\n",
    "        e_pred_test_US = unscale_data(e_pred_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_pred_test_US = unscale_data(e_prime_pred_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        batch_loss_test = loss_fn(\n",
    "            displacements_test,\n",
    "            e_target_test,\n",
    "            e_prime_target_test,\n",
    "            Model=test_model,\n",
    "            Dataset_parameters=model_data.Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        loss_test += batch_loss_test\n",
    "        test_count += 1\n",
    "\n",
    "        avg_e_abs_error = avg_abs_error(e_pred_test_US,e_target_test_US)\n",
    "        avg_e_prime_abs_error = avg_abs_error(e_prime_pred_test_US,e_prime_target_test_US)\n",
    "\n",
    "    avg_loss_test = loss_test / test_count\n",
    "    zero_val_e, _ = test_model(scale_data(jnp.zeros_like(test_batches[0]['displacements']),data_params=model_data.Dataset_parameters['displacements']), dataset_params=model_data.Dataset_parameters)\n",
    "    zero_val_e = unscale_data(zero_val_e,data_params=model_data.Dataset_parameters['target_e'])\n",
    "    test_e_zero_error = avg_abs_error(zero_val_e, jnp.zeros_like(zero_val_e))\n",
    "\n",
    "    return avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3504",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average absolute error for e is 2340.17724609375 in the test set\n",
      "the average absolute error for e prime is 26513812.0 in the test set\n",
      "the absolute zero error for e is 45.74467468261719 in the test set\n",
      "The average loss across the training set is 20663.365234375\n",
      "The average absolute error for e is 11.73261833190918 in the training set\n",
      "the average absolute error for e prime is 1843936.75 in the training set\n",
      "the absolute zero error for e is 45.74467468261719 in the training set\n"
     ]
    }
   ],
   "source": [
    "avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error = test_model(model_data,test_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    "avg_loss_training, avg_e_abs_error_training, avg_e_prime_abs_error_training, test_e_zero_error_training = test_model(model_data,train_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    " \n",
    "print(f\"The average absolute error for e is {avg_e_abs_error} in the test set\") \n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error} in the test set\") \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error} in the test set\") \n",
    "\n",
    "print(f\"The average loss across the training set is {avg_loss_test}\")\n",
    "print(f\"The average absolute error for e is {avg_e_abs_error_training} in the training set\")\n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error_training} in the training set\")  \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error_training} in the training set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
