{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc34597",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae85666",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 1000\n",
    "alpha = 1.0\n",
    "gamma = 2.5\n",
    "lambda_ = 0.1\n",
    "Learn_Rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 40\n",
    "train_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2340, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(12340, 152, 3)\n",
      "(12340, 1)\n",
      "(12340, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)[0:2340]\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)[0:2340]\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)[0:2340]\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = jnp.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec14bee",
   "metadata": {},
   "source": [
    "Pre and post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6607d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data = data[:split_idx]\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "\n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']\n",
    "\n",
    "def add_square_feature(data,*,axis, feature_number):\n",
    "    new_feature = jnp.square(data)\n",
    "    new_data = jnp.concatenate([data,new_feature],axis=axis)\n",
    "    feature_number += 1\n",
    "    return new_data, feature_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset - Note: need to remove input scaling in the dataset as its done in the model, need to add a parameter calulator for the input that concatenates the square data then gets params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4221141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING RAW DATASET\n",
      "Key: 'displacements'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 912)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340,)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e_prime'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 456)\n",
      "  - Dtype: float32\n",
      "------------------------------\n",
      "[2.8900618e-03 2.8923051e-03 2.8872348e-03 2.8968814e-03 2.8679431e-03\n",
      " 2.8880290e-03 2.8918695e-03 2.9087116e-03 2.8939452e-03 2.8820811e-03\n",
      " 2.9206073e-03 2.8910111e-03 2.9055146e-03 2.8789211e-03 2.8964309e-03\n",
      " 2.9044275e-03 2.8826289e-03 2.8897757e-03 2.8964640e-03 2.8790655e-03\n",
      " 2.8754773e-03 2.9039108e-03 2.8681895e-03 2.8857610e-03 2.8790105e-03\n",
      " 2.8741271e-03 2.8825605e-03 2.8848723e-03 2.8908534e-03 2.8906178e-03\n",
      " 2.8912819e-03 2.9047849e-03 2.8822962e-03 2.8798738e-03 2.8724291e-03\n",
      " 2.8842089e-03 2.8919308e-03 2.9025357e-03 2.8885130e-03 2.8751364e-03\n",
      " 2.9005159e-03 2.8780780e-03 2.8749481e-03 2.9029169e-03 2.8852988e-03\n",
      " 2.9096350e-03 2.8920732e-03 2.8924858e-03 2.8760002e-03 2.8759874e-03\n",
      " 2.8852047e-03 2.8993997e-03 2.8990195e-03 2.8848378e-03 2.8943804e-03\n",
      " 2.8729623e-03 2.8791581e-03 2.9099225e-03 2.8841663e-03 2.8785625e-03\n",
      " 2.8785968e-03 2.8893021e-03 2.9012342e-03 2.8704887e-03 2.9012775e-03\n",
      " 2.8994475e-03 2.8753628e-03 2.8982174e-03 2.8888276e-03 2.9001450e-03\n",
      " 2.8761991e-03 2.8692791e-03 2.8874371e-03 2.8721180e-03 2.9099158e-03\n",
      " 2.8885810e-03 2.9028070e-03 2.8926237e-03 2.9155444e-03 2.8820261e-03\n",
      " 2.8793241e-03 2.8873968e-03 2.8967799e-03 2.8732242e-03 2.8811705e-03\n",
      " 2.9026722e-03 2.8826084e-03 2.8698333e-03 2.8885957e-03 2.8728703e-03\n",
      " 2.8983606e-03 2.8716447e-03 2.8818429e-03 2.8899268e-03 2.8753781e-03\n",
      " 2.8865794e-03 2.9038324e-03 2.8796226e-03 2.8770261e-03 2.8976691e-03\n",
      " 2.8860040e-03 2.8960307e-03 2.8921983e-03 2.8969017e-03 2.8929973e-03\n",
      " 2.8986938e-03 2.8947322e-03 2.8933315e-03 2.8814897e-03 2.8910770e-03\n",
      " 2.8957580e-03 2.9020733e-03 2.8769898e-03 2.8860762e-03 2.8808278e-03\n",
      " 2.8987909e-03 2.8670672e-03 2.8786596e-03 2.9023944e-03 2.8810855e-03\n",
      " 2.8799707e-03 2.9074678e-03 2.8781742e-03 2.8978393e-03 2.8749143e-03\n",
      " 2.8850413e-03 2.8829456e-03 2.8790433e-03 2.8790860e-03 2.8930339e-03\n",
      " 2.8629811e-03 2.8729278e-03 2.8877510e-03 2.8944607e-03 2.8879428e-03\n",
      " 2.8775299e-03 2.8913640e-03 2.8694780e-03 2.8890476e-03 2.9010910e-03\n",
      " 2.8825002e-03 2.8768948e-03 2.8843151e-03 2.8861687e-03 2.8732223e-03\n",
      " 2.8827232e-03 2.8951243e-03 2.8751788e-03 2.8845959e-03 2.8991380e-03\n",
      " 2.8957273e-03 2.8800848e-03 2.8864490e-03 2.8637573e-03 2.8759756e-03\n",
      " 2.8982672e-03 2.8925082e-03 2.8754035e-03 2.8655350e-03 2.9072361e-03\n",
      " 2.8840208e-03 2.8671431e-03 2.8702056e-03 2.8981462e-03 2.9110441e-03\n",
      " 2.8806971e-03 2.8842206e-03 2.8905727e-03 2.8772056e-03 2.8848464e-03\n",
      " 2.8946397e-03 2.8846571e-03 2.8866827e-03 2.8976074e-03 2.8959732e-03\n",
      " 2.8692421e-03 2.8805844e-03 2.8822483e-03 2.8525963e-03 2.8824725e-03\n",
      " 2.8811942e-03 2.8834944e-03 2.8821137e-03 2.9004230e-03 2.8883971e-03\n",
      " 2.9057763e-03 2.8896262e-03 2.8834008e-03 2.8939946e-03 2.8898597e-03\n",
      " 2.8742342e-03 2.8885663e-03 2.8904621e-03 2.8984321e-03 2.8906679e-03\n",
      " 2.8993820e-03 2.8892925e-03 2.8777285e-03 2.8891372e-03 2.8806231e-03\n",
      " 2.9028293e-03 2.8943624e-03 2.8821609e-03 2.9024428e-03 2.8757765e-03\n",
      " 2.8940972e-03 2.8988516e-03 2.8992912e-03 2.8973438e-03 2.8886225e-03\n",
      " 2.9176921e-03 2.9103742e-03 2.8975820e-03 2.8696132e-03 2.9150075e-03\n",
      " 2.8877812e-03 2.9000062e-03 2.8772936e-03 2.9008060e-03 2.8905550e-03\n",
      " 2.8867768e-03 2.8852744e-03 2.9023709e-03 2.9070505e-03 2.8966009e-03\n",
      " 2.9012787e-03 2.8945529e-03 2.8847554e-03 2.8992298e-03 2.8946840e-03\n",
      " 2.9092887e-03 2.8685674e-03 2.9078447e-03 2.8801188e-03 2.8957513e-03\n",
      " 2.8768019e-03 2.8883484e-03 2.8974088e-03 2.8820802e-03 2.8798124e-03\n",
      " 2.8937934e-03 2.8803032e-03 2.8983750e-03 2.8733290e-03 2.8790720e-03\n",
      " 2.8953108e-03 2.8915997e-03 2.8989436e-03 2.9004086e-03 2.8718500e-03\n",
      " 2.8926388e-03 2.8881740e-03 2.8770545e-03 2.8786182e-03 2.8904993e-03\n",
      " 2.8834974e-03 2.8714542e-03 2.8840606e-03 2.8890583e-03 2.8672556e-03\n",
      " 2.8882897e-03 2.8910367e-03 2.8859128e-03 2.9079374e-03 2.9061730e-03\n",
      " 2.8803831e-03 2.8811824e-03 2.8642840e-03 2.8754999e-03 2.8846154e-03\n",
      " 2.9020559e-03 2.9055232e-03 2.9009364e-03 2.8871750e-03 2.8742149e-03\n",
      " 2.9063828e-03 2.8969250e-03 2.8738480e-03 2.8972479e-03 2.8799160e-03\n",
      " 2.8699529e-03 2.8735278e-03 2.9028484e-03 2.8901810e-03 2.8984016e-03\n",
      " 2.8710936e-03 2.8874294e-03 2.9016885e-03 2.9051343e-03 2.8937247e-03\n",
      " 2.8664924e-03 2.8869316e-03 2.8949673e-03 2.8663336e-03 2.8710179e-03\n",
      " 2.8785951e-03 2.9009120e-03 2.8794373e-03 2.8896043e-03 2.8942160e-03\n",
      " 2.8903489e-03 2.9077458e-03 2.9021171e-03 2.8720242e-03 2.8764519e-03\n",
      " 2.8931424e-03 2.8729474e-03 2.8863805e-03 2.8997639e-03 2.8759651e-03\n",
      " 2.8882609e-03 2.8966684e-03 2.8767786e-03 2.8723700e-03 2.8859221e-03\n",
      " 2.8855088e-03 2.9208541e-03 2.8755483e-03 2.8830576e-03 2.8828897e-03\n",
      " 2.8783707e-03 2.8736789e-03 2.8843025e-03 2.8902374e-03 2.8859365e-03\n",
      " 2.8662866e-03 2.8886171e-03 2.8862462e-03 2.8986563e-03 2.8817069e-03\n",
      " 2.8907775e-03 2.9027208e-03 2.8929512e-03 2.8914425e-03 2.8677604e-03\n",
      " 2.8811349e-03 2.8791178e-03 2.8827817e-03 2.8913475e-03 2.8746279e-03\n",
      " 2.8789954e-03 2.8848106e-03 2.8824117e-03 2.9044193e-03 2.8831721e-03\n",
      " 2.8715688e-03 2.8854890e-03 2.9000745e-03 2.8933263e-03 2.9113700e-03\n",
      " 2.8755220e-03 2.8889601e-03 2.8746428e-03 2.8701043e-03 2.8659452e-03\n",
      " 2.8809048e-03 2.8828715e-03 2.8834576e-03 2.8849544e-03 2.9118147e-03\n",
      " 2.8957450e-03 2.8729925e-03 2.8701937e-03 2.8966202e-03 2.8970041e-03\n",
      " 2.8840681e-03 2.8962416e-03 2.8750298e-03 2.8685979e-03 2.8911242e-03\n",
      " 2.8848758e-03 2.8865472e-03 2.9080452e-03 2.8804764e-03 2.8665981e-03\n",
      " 2.8715206e-03 2.8793816e-03 2.8842520e-03 2.8848227e-03 2.8960898e-03\n",
      " 2.8692116e-03 2.8680400e-03 2.8989038e-03 2.8700142e-03 2.8823405e-03\n",
      " 2.9083192e-03 2.8881012e-03 2.8812888e-03 2.8950996e-03 2.8745113e-03\n",
      " 2.8731150e-03 2.8883745e-03 2.8826711e-03 2.8818473e-03 2.8966779e-03\n",
      " 2.8641073e-03 2.8860641e-03 2.8777267e-03 2.8769921e-03 2.8996961e-03\n",
      " 2.8752850e-03 2.9222132e-03 2.8892553e-03 2.8786596e-03 2.8923710e-03\n",
      " 2.8944311e-03 2.9068473e-03 2.8758119e-03 2.8835707e-03 2.8828324e-03\n",
      " 2.8663429e-03 2.8918420e-03 2.8699227e-03 2.8911147e-03 2.8824655e-03\n",
      " 2.8837582e-03 2.8788981e-03 2.8946612e-03 2.8836897e-03 2.8821172e-03\n",
      " 2.8774228e-03 2.8813777e-03 2.9072373e-03 2.8562893e-03 2.8880450e-03\n",
      " 2.8981834e-03 2.8817595e-03 2.8567738e-03 2.8679071e-03 2.8798382e-03\n",
      " 2.8930320e-03 2.8918737e-03 2.8964388e-03 2.8732074e-03 2.8901196e-03\n",
      " 2.8935352e-03 2.8849118e-03 2.8720445e-03 2.8799444e-03 2.8908306e-03\n",
      " 2.8986488e-03 2.9051569e-03 2.8937289e-03 2.8723450e-03 2.8938870e-03\n",
      " 2.9034333e-03 2.8801861e-03 2.8734652e-03 2.8676761e-03 2.8779353e-03\n",
      " 2.8635426e-03 2.8865170e-03 2.8993515e-03 2.8735909e-03 2.8843912e-03\n",
      " 2.9060366e-03 7.4579061e-06 7.4430823e-06 7.4606323e-06 7.4949135e-06\n",
      " 7.4093687e-06 7.4057098e-06 7.5078610e-06 7.5121320e-06 7.4961599e-06\n",
      " 7.4500035e-06 7.4723639e-06 7.4855980e-06 7.5040903e-06 7.4869599e-06\n",
      " 7.4793525e-06 7.5350154e-06 7.4317009e-06 7.4269001e-06 7.4688869e-06\n",
      " 7.4915356e-06 7.3467904e-06 7.4635373e-06 7.3984720e-06 7.3881397e-06\n",
      " 7.4397326e-06 7.4180616e-06 7.4838858e-06 7.4306704e-06 7.4165496e-06\n",
      " 7.4702475e-06 7.4579943e-06 7.4558952e-06 7.4318950e-06 7.4700133e-06\n",
      " 7.4268119e-06 7.4201134e-06 7.4847467e-06 7.4702980e-06 7.4447262e-06\n",
      " 7.4386471e-06 7.4652789e-06 7.4211257e-06 7.4574291e-06 7.5024286e-06\n",
      " 7.4636655e-06 7.4914597e-06 7.4204936e-06 7.4999271e-06 7.3421152e-06\n",
      " 7.4077479e-06 7.4633585e-06 7.4457489e-06 7.4950331e-06 7.4453769e-06\n",
      " 7.4757995e-06 7.4090367e-06 7.4668224e-06 7.4998125e-06 7.4894247e-06\n",
      " 7.4699806e-06 7.4533850e-06 7.4509039e-06 7.4469008e-06 7.4459072e-06\n",
      " 7.4893464e-06 7.3947235e-06 7.4240475e-06 7.4834716e-06 7.4105428e-06\n",
      " 7.4466557e-06 7.4442596e-06 7.4194272e-06 7.4885579e-06 7.4144050e-06\n",
      " 7.5139806e-06 7.4264913e-06 7.4773325e-06 7.5275448e-06 7.4729473e-06\n",
      " 7.4837676e-06 7.4812147e-06 7.4406739e-06 7.4681966e-06 7.4686764e-06\n",
      " 7.4280965e-06 7.4956947e-06 7.4651171e-06 7.4131781e-06 7.4670052e-06\n",
      " 7.4257382e-06 7.4810264e-06 7.4293025e-06 7.4306422e-06 7.4958712e-06\n",
      " 7.4615664e-06 7.4575601e-06 7.4895765e-06 7.4851032e-06 7.4206523e-06\n",
      " 7.4541531e-06 7.4231566e-06 7.4811296e-06 7.5045464e-06 7.4336135e-06\n",
      " 7.4173836e-06 7.4445397e-06 7.4878762e-06 7.4686845e-06 7.4152154e-06\n",
      " 7.4715158e-06 7.4133550e-06 7.5147136e-06 7.5055427e-06 7.4560944e-06\n",
      " 7.4301993e-06 7.5075209e-06 7.3769952e-06 7.4578302e-06 7.4478539e-06\n",
      " 7.3958909e-06 7.4381687e-06 7.4929280e-06 7.3828951e-06 7.4554255e-06\n",
      " 7.4149666e-06 7.4675922e-06 7.4425898e-06 7.4614372e-06 7.3955239e-06\n",
      " 7.4886175e-06 7.4397913e-06 7.4668260e-06 7.4384493e-06 7.4530822e-06\n",
      " 7.4624036e-06 7.4824734e-06 7.4635573e-06 7.4548811e-06 7.4492718e-06\n",
      " 7.4443137e-06 7.4812051e-06 7.4217355e-06 7.4604277e-06 7.4895611e-06\n",
      " 7.4437389e-06 7.3883407e-06 7.4478116e-06 7.4260374e-06 7.3903911e-06\n",
      " 7.4754666e-06 7.5271141e-06 7.4235277e-06 7.4687623e-06 7.4096652e-06\n",
      " 7.4242585e-06 7.4300442e-06 7.4157201e-06 7.4109848e-06 7.4114237e-06\n",
      " 7.4922250e-06 7.4872810e-06 7.4315208e-06 7.4806626e-06 7.4707882e-06\n",
      " 7.5172929e-06 7.4386021e-06 7.4560257e-06 7.4730342e-06 7.4529075e-06\n",
      " 7.4853483e-06 7.4757309e-06 7.4253298e-06 7.4933128e-06 7.4487780e-06\n",
      " 7.4552418e-06 7.4261293e-06 7.4170357e-06 7.4533809e-06 7.3588608e-06\n",
      " 7.4982077e-06 7.3584220e-06 7.4138056e-06 7.4619770e-06 7.4386840e-06\n",
      " 7.4864174e-06 7.4838422e-06 7.4807394e-06 7.4130289e-06 7.4783698e-06\n",
      " 7.4570376e-06 7.4253585e-06 7.4663035e-06 7.4788459e-06 7.4713453e-06\n",
      " 7.4222939e-06 7.4564987e-06 7.4586683e-06 7.4831751e-06 7.4757158e-06\n",
      " 7.4850141e-06 7.4679124e-06 7.4684667e-06 7.4187087e-06 7.4778968e-06\n",
      " 7.4610348e-06 7.4830014e-06 7.4704321e-06 7.4288978e-06 7.4197801e-06\n",
      " 7.4205091e-06 7.4450145e-06 7.4789764e-06 7.4642862e-06 7.4911231e-06\n",
      " 7.4695313e-06 7.4496506e-06 7.4921222e-06 7.4061572e-06 7.4772079e-06\n",
      " 7.4750692e-06 7.4569421e-06 7.4403220e-06 7.4824352e-06 7.4431741e-06\n",
      " 7.4750910e-06 7.4745408e-06 7.4694717e-06 7.4645150e-06 7.4577520e-06\n",
      " 7.4653908e-06 7.4936233e-06 7.3822107e-06 7.5206981e-06 7.3765264e-06\n",
      " 7.4972759e-06 7.4681661e-06 7.4401992e-06 7.5422245e-06 7.4168624e-06\n",
      " 7.3973470e-06 7.4698009e-06 7.4341137e-06 7.4895747e-06 7.3848150e-06\n",
      " 7.4542345e-06 7.4799232e-06 7.4373711e-06 7.4756836e-06 7.4656750e-06\n",
      " 7.4626782e-06 7.4419836e-06 7.4878940e-06 7.3600295e-06 7.4410809e-06\n",
      " 7.4721452e-06 7.4111763e-06 7.4315653e-06 7.3912183e-06 7.4970771e-06\n",
      " 7.4448681e-06 7.4696295e-06 7.4627242e-06 7.4403420e-06 7.4692139e-06\n",
      " 7.4744821e-06 7.4152922e-06 7.3826068e-06 7.4097375e-06 7.4318623e-06\n",
      " 7.4555610e-06 7.4881914e-06 7.5358193e-06 7.4771938e-06 7.4501227e-06\n",
      " 7.4171512e-06 7.4660315e-06 7.4521563e-06 7.4210097e-06 7.4399418e-06\n",
      " 7.4916161e-06 7.3885071e-06 7.4042528e-06 7.4544732e-06 7.4618542e-06\n",
      " 7.4860723e-06 7.4311974e-06 7.4529930e-06 7.5178527e-06 7.4810446e-06\n",
      " 7.4464006e-06 7.4168529e-06 7.5339071e-06 7.4179520e-06 7.4390709e-06\n",
      " 7.4352133e-06 7.4664163e-06 7.4935551e-06 7.4799309e-06 7.4526083e-06\n",
      " 7.4242980e-06 7.4749223e-06 7.4592194e-06 7.5126345e-06 7.4382519e-06\n",
      " 7.4471227e-06 7.4899631e-06 7.3782671e-06 7.5255298e-06 7.4743766e-06\n",
      " 7.4327249e-06 7.4557079e-06 7.4953982e-06 7.4604591e-06 7.4627610e-06\n",
      " 7.4585928e-06 7.3650549e-06 7.4814084e-06 7.4563759e-06 7.4160516e-06\n",
      " 7.4300115e-06 7.4375625e-06 7.4601712e-06 7.4464638e-06 7.4551704e-06\n",
      " 7.4555619e-06 7.5066196e-06 7.4553418e-06 7.4718068e-06 7.4886639e-06\n",
      " 7.4183754e-06 7.4152485e-06 7.4823929e-06 7.4805826e-06 7.4867530e-06\n",
      " 7.4262412e-06 7.3976103e-06 7.5191952e-06 7.4634972e-06 7.4235991e-06\n",
      " 7.4502464e-06 7.4482286e-06 7.4247559e-06 7.4759205e-06 7.4760328e-06\n",
      " 7.4754412e-06 7.4133541e-06 7.4671993e-06 7.4788436e-06 7.4611730e-06\n",
      " 7.5093694e-06 7.4014470e-06 7.4783970e-06 7.4754244e-06 7.4650152e-06\n",
      " 7.4511127e-06 7.4092532e-06 7.4126533e-06 7.4699501e-06 7.4364370e-06\n",
      " 7.4416189e-06 7.5219600e-06 7.3989090e-06 7.4500413e-06 7.4825230e-06\n",
      " 7.5235589e-06 7.5232861e-06 7.4803529e-06 7.4495338e-06 7.3999290e-06\n",
      " 7.4726440e-06 7.4195582e-06 7.4182581e-06 7.4016662e-06 7.3748388e-06\n",
      " 7.4084032e-06 7.4471136e-06 7.3836018e-06 7.4379391e-06 7.4489435e-06\n",
      " 7.4852828e-06 7.4513650e-06 7.4422178e-06 7.5210082e-06 7.4020300e-06\n",
      " 7.3968517e-06 7.4724144e-06 7.4342488e-06 7.4347890e-06 7.4465538e-06\n",
      " 7.4888540e-06 7.4210061e-06 7.3711171e-06 7.4566919e-06 7.4059294e-06\n",
      " 7.4681507e-06 7.3789074e-06 7.4955487e-06 7.4199061e-06 7.4114287e-06\n",
      " 7.5250441e-06 7.4201462e-06 7.5411922e-06 7.5055523e-06 7.4340442e-06\n",
      " 7.4859977e-06 7.4536474e-06 7.4856835e-06 7.4663949e-06 7.4081372e-06\n",
      " 7.3890151e-06 7.4249724e-06 7.4470427e-06 7.4161385e-06 7.4751251e-06\n",
      " 7.4638906e-06 7.3830524e-06 7.4556178e-06 7.4053905e-06 7.4624932e-06\n",
      " 7.4613645e-06 7.4642899e-06 7.4399081e-06 7.5170074e-06 7.3878255e-06\n",
      " 7.4853224e-06 7.4605550e-06 7.4195727e-06 7.4284808e-06 7.3673118e-06\n",
      " 7.4789286e-06 7.4671466e-06 7.4589047e-06 7.4691084e-06 7.4357399e-06\n",
      " 7.4906034e-06 7.4714671e-06 7.4665063e-06 7.3905071e-06 7.4332429e-06\n",
      " 7.4473182e-06 7.5001626e-06 7.4601153e-06 7.5024527e-06 7.4132254e-06\n",
      " 7.4235168e-06 7.4920440e-06 7.4587424e-06 7.4313430e-06 7.3867564e-06\n",
      " 7.4263185e-06 7.3997735e-06 7.4595837e-06 7.4535137e-06 7.4128588e-06\n",
      " 7.4702966e-06 7.4394397e-06]\n"
     ]
    }
   ],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "input_dataset = input_dataset.reshape((input_dataset.shape[0],456))\n",
    "displacement_dim = input_dataset.shape[1]\n",
    "\n",
    "# add features\n",
    "num_features = 0\n",
    "input_dataset, num_features = add_square_feature(input_dataset,axis=1, feature_number=num_features)\n",
    "\n",
    "target_e_dataset = target_e_dataset.reshape((target_e_dataset.shape[0],))\n",
    "target_e_prime_dataset = target_e_prime_dataset.reshape((target_e_prime_dataset.shape[0],456))\n",
    "\n",
    "params_dict_displacement = mean_and_std_dev(input_dataset,train_split=train_split)\n",
    "params_dict_target_e = mean_and_std_dev(target_e_dataset,train_split=train_split)\n",
    "params_dict_target_e_prime = mean_and_std_dev(target_e_prime_dataset,train_split=train_split)\n",
    "\n",
    "input_dataset_scaled = scale_data(input_dataset,data_params=params_dict_displacement)\n",
    "target_e_dataset_scaled = scale_data(target_e_dataset, data_params=params_dict_target_e)\n",
    "target_e_prime_dataset_scaled = scale_data(target_e_prime_dataset, data_params=params_dict_target_e_prime)\n",
    "\n",
    "Dataset_parameters = {\n",
    "    'displacements':params_dict_displacement,\n",
    "    'target_e':params_dict_target_e,\n",
    "    'target_e_prime':params_dict_target_e_prime,\n",
    "    'num_features':num_features,\n",
    "    'standard_displacement_dim':displacement_dim\n",
    "}\n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset_scaled, \n",
    "    'target_e':target_e_dataset_scaled,\n",
    "    'target_e_prime':target_e_prime_dataset_scaled\n",
    "}\n",
    "\n",
    "print(\"INSPECTING RAW DATASET\")\n",
    "for key, value in Dataset.items():\n",
    "    print(f\"Key: '{key}'\")\n",
    "    print(f\"  - Type: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  - Shape: {value.shape}\")\n",
    "    else:\n",
    "        print(\"  - No shape attribute.\")\n",
    "    if hasattr(value, 'dtype'):\n",
    "        print(f\"  - Dtype: {value.dtype}\")\n",
    "print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b799cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1932328\n",
      "2.932326\n",
      "4.1916647\n"
     ]
    }
   ],
   "source": [
    "print(Dataset['displacements'][0][1])\n",
    "print(Dataset['target_e'][0])\n",
    "print(Dataset['target_e_prime'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.Module):\n",
    "    \"\"\"\n",
    "    Model architecture\n",
    "    Inputs: standardised displacements and all engineered features and the parameters of the dataset\n",
    "    Outputs: standardised energy value and standardised energy derivatives wrt each of the displacements\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in,rngs=rngs)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in,rngs=rngs)\n",
    "        self.output_layer = Linear(din=dim_hidden2_in,dout=dim_out,rngs=rngs)\n",
    "        self.silu = SiLU\n",
    "\n",
    "    def forwardPass(self,x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.output_layer(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "    def __call__(self,x_in,dataset_params):\n",
    "        \n",
    "        e = jax.vmap(self.forwardPass)(x_in)\n",
    "        dedx = jax.vmap(jax.grad(self.forwardPass))\n",
    "        e_prime_raw = dedx(x_in)\n",
    "        e_prime_raw_lin_ft = e_prime_raw[:, :dataset_params['standard_displacement_dim']]\n",
    "\n",
    "        sigma_e = dataset_params['target_e']['std_dev']\n",
    "        sigma_x = dataset_params['displacements']['std_dev']\n",
    "        sigma_x_linear = sigma_x[:dataset_params['standard_displacement_dim']]\n",
    "        mean_e_prime = dataset_params['target_e_prime']['mean']\n",
    "        sigma_e_prime = dataset_params['target_e_prime']['std_dev']\n",
    "\n",
    "        e_prime_physical = e_prime_raw_lin_ft * (sigma_e/sigma_x_linear)\n",
    "        e_prime = (e_prime_physical - mean_e_prime) / sigma_e_prime\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(x, Dataset_parameters)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime)**2)\n",
    "\n",
    "    mean_e = Dataset_parameters['target_e']['mean']\n",
    "    std_dev_e = Dataset_parameters['target_e']['std_dev']\n",
    "    target_zero = (0 - mean_e) / std_dev_e\n",
    "    \n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "    prediction_zero, _ = Model(x_zero, Dataset_parameters)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any \n",
    "    state: Any\n",
    "    alpha: float \n",
    "    gamma: float \n",
    "    lambda_: float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(params,state,opt_state,batch,*,graph_def,Dataset_parameters,alpha,gamma,lambda_):\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(params_,state_):\n",
    "        Model = nnx.merge(graph_def,params_,state_)\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=0)(params, state) \n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "\n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e88cb1",
   "metadata": {},
   "source": [
    "Batch Creator and test set creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9981b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_batch_dataset(dataset, batch_size, test_split=0.2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets, then yields batches for each.\n",
    "    Returns: (train_batches, test_batches).\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    split_idx = int(N * (1 - test_split))\n",
    "    train_idx = indices[:split_idx]\n",
    "    test_idx = indices[split_idx:]\n",
    "\n",
    "    def batch_indices(idx):\n",
    "        batch_num = len(idx) // batch_size\n",
    "        for i in range(batch_num):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            batch = {key: value[batch_idx] for key, value in dataset.items()}\n",
    "            yield batch\n",
    "\n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e467e7e",
   "metadata": {},
   "source": [
    "Create test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df10eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = split_and_batch_dataset(\n",
    "    Dataset, \n",
    "    Batch_size, \n",
    "    test_split=(1 - train_split), \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (912,) and (1824,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m batch_count = \u001b[32m0\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_batches,desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEpochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     new_params, new_state, new_opt_state, loss_batch = training_step(\n\u001b[32m     31\u001b[39m         train_state.params,\n\u001b[32m     32\u001b[39m         train_state.state,\n\u001b[32m     33\u001b[39m         opt_state,\n\u001b[32m     34\u001b[39m         batch,\n\u001b[32m     35\u001b[39m         graph_def=train_state.graph_def,\n\u001b[32m     36\u001b[39m         Dataset_parameters=Dataset_parameters,\n\u001b[32m     37\u001b[39m         alpha=train_state.alpha,\n\u001b[32m     38\u001b[39m         gamma=train_state.gamma,\n\u001b[32m     39\u001b[39m         lambda_=train_state.lambda_\n\u001b[32m     40\u001b[39m     )\n\u001b[32m     42\u001b[39m     opt_state = new_opt_state\n\u001b[32m     43\u001b[39m     train_state.params = new_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\flax\\nnx\\transforms\\compilation.py:431\u001b[39m, in \u001b[36mJitWrapped.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m graph.update_context(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    430\u001b[39m   pure_args, pure_kwargs = \u001b[38;5;28mself\u001b[39m._get_pure_args_kwargs(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m   pure_args_out, pure_kwargs_out, pure_out = \u001b[38;5;28mself\u001b[39m.jitted_fn(\n\u001b[32m    432\u001b[39m     *pure_args, **pure_kwargs\n\u001b[32m    433\u001b[39m   )\n\u001b[32m    434\u001b[39m   out = \u001b[38;5;28mself\u001b[39m._get_non_pure_out(pure_args_out, pure_kwargs_out, pure_out)\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\flax\\nnx\\transforms\\compilation.py:126\u001b[39m, in \u001b[36mJitFn.__call__\u001b[39m\u001b[34m(self, *pure_args, **pure_kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *pure_args, **pure_kwargs):\n\u001b[32m    119\u001b[39m   args, kwargs = extract.from_tree(\n\u001b[32m    120\u001b[39m     (pure_args, pure_kwargs),\n\u001b[32m    121\u001b[39m     merge_fn=_jit_merge_fn,\n\u001b[32m    122\u001b[39m     ctxtag=\u001b[38;5;28mself\u001b[39m.ctxtag,\n\u001b[32m    123\u001b[39m     is_inner=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    124\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m   out = \u001b[38;5;28mself\u001b[39m.f(*args, **kwargs)\n\u001b[32m    128\u001b[39m   args_out, kwargs_out = extract.clear_non_graph_nodes((args, kwargs))\n\u001b[32m    129\u001b[39m   pure_args_out, pure_kwargs_out, pure_out = extract.to_tree(\n\u001b[32m    130\u001b[39m     (args_out, kwargs_out, out),\n\u001b[32m    131\u001b[39m     prefix=(\u001b[38;5;28mself\u001b[39m.in_shardings, \u001b[38;5;28mself\u001b[39m.kwarg_shardings, \u001b[38;5;28mself\u001b[39m.out_shardings),\n\u001b[32m    132\u001b[39m     ctxtag=\u001b[38;5;28mself\u001b[39m.ctxtag,\n\u001b[32m    133\u001b[39m     split_fn=_jit_split_fn,\n\u001b[32m    134\u001b[39m   )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtraining_step\u001b[39m\u001b[34m(params, state, opt_state, batch, graph_def, Dataset_parameters, alpha, gamma, lambda_)\u001b[39m\n\u001b[32m     10\u001b[39m     loss = loss_fn(\n\u001b[32m     11\u001b[39m         disp_in,\n\u001b[32m     12\u001b[39m         e_target,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m         lam=lambda_\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=\u001b[32m0\u001b[39m)(params, state) \n\u001b[32m     23\u001b[39m updates, new_opt_state = optimiser.update(grads, opt_state, params)\n\u001b[32m     24\u001b[39m new_params = optax.apply_updates(params, updates)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\flax\\nnx\\graph.py:2051\u001b[39m, in \u001b[36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2048\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m   2049\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_context_manager_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m   2050\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\flax\\nnx\\transforms\\autodiff.py:163\u001b[39m, in \u001b[36m_grad_general.<locals>.grad_wrapper\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    151\u001b[39m pure_args = extract.to_tree(\n\u001b[32m    152\u001b[39m   args, prefix=arg_filters, split_fn=_grad_split_fn, ctxtag=\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    153\u001b[39m )\n\u001b[32m    155\u001b[39m gradded_fn = transform(\n\u001b[32m    156\u001b[39m   GradFn(f, has_aux, nondiff_states),\n\u001b[32m    157\u001b[39m   argnums=jax_argnums,\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m   allow_int=allow_int,\n\u001b[32m    161\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m fn_out = gradded_fn(*pure_args)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_grads\u001b[39m(grads):\n\u001b[32m    166\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m jax.tree.map(\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x.state \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, extract.NodeStates) \u001b[38;5;28;01melse\u001b[39;00m x,\n\u001b[32m    168\u001b[39m     grads,\n\u001b[32m    169\u001b[39m     is_leaf=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, extract.NodeStates),\n\u001b[32m    170\u001b[39m   )\n",
      "    \u001b[31m[... skipping hidden 16 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\flax\\nnx\\transforms\\autodiff.py:88\u001b[39m, in \u001b[36mGradFn.__call__\u001b[39m\u001b[34m(self, *pure_args)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx.merge(value.graphdef, value.state, nondiff)\n\u001b[32m     84\u001b[39m args = extract.from_tree(\n\u001b[32m     85\u001b[39m   pure_args, merge_fn=_grad_merge_fn, ctxtag=\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m, is_inner=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     86\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m out = \u001b[38;5;28mself\u001b[39m.f(*args)\n\u001b[32m     90\u001b[39m args_out = extract.clear_non_graph_nodes(args)\n\u001b[32m     91\u001b[39m pure_args_out, pure_out = extract.to_tree((args_out, out), ctxtag=\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtraining_step.<locals>.wrapped_loss_fn\u001b[39m\u001b[34m(params_, state_)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_loss_fn\u001b[39m(params_,state_):\n\u001b[32m      9\u001b[39m     Model = nnx.merge(graph_def,params_,state_)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     loss = loss_fn(\n\u001b[32m     11\u001b[39m         disp_in,\n\u001b[32m     12\u001b[39m         e_target,\n\u001b[32m     13\u001b[39m         e_prime_target,\n\u001b[32m     14\u001b[39m         Model=Model,\n\u001b[32m     15\u001b[39m         Dataset_parameters=Dataset_parameters,\n\u001b[32m     16\u001b[39m         alpha=alpha,\n\u001b[32m     17\u001b[39m         gamma=gamma,\n\u001b[32m     18\u001b[39m         lam=lambda_\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mloss_fn\u001b[39m\u001b[34m(x, target_e, target_e_prime, Model, Dataset_parameters, alpha, gamma, lam)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_fn\u001b[39m(x: jax.Array, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    Calculates the loss of a model, works to minimise the mean square error of both \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    the strain energy prediction and the strain energy derivative prediction,\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    whilst forcing the function through zero.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     prediction_e, prediction_e_prime = Model(x, Dataset_parameters)\n\u001b[32m     11\u001b[39m     loss_e = jnp.mean((prediction_e - target_e)**\u001b[32m2\u001b[39m)\n\u001b[32m     12\u001b[39m     loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime)**\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36menergy_prediction.__call__\u001b[39m\u001b[34m(self, x_in, dataset_params)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,x_in,dataset_params):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     e = jax.vmap(\u001b[38;5;28mself\u001b[39m.forwardPass)(x_in)\n\u001b[32m     25\u001b[39m     dedx = jax.vmap(jax.grad(\u001b[38;5;28mself\u001b[39m.forwardPass))\n\u001b[32m     26\u001b[39m     e_prime_raw = dedx(x_in)\n",
      "    \u001b[31m[... skipping hidden 7 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36menergy_prediction.forwardPass\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforwardPass\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.layer1(x)\n\u001b[32m     16\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.silu(x)\n\u001b[32m     17\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mLinear.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,x: jax.Array):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m(x @ \u001b[38;5;28mself\u001b[39m.W + \u001b[38;5;28mself\u001b[39m.b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:1083\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.aval, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)(\u001b[38;5;28mself\u001b[39m, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:583\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    581\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(*args)\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[31m[... skipping hidden 15 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\jax\\_src\\numpy\\tensor_contractions.py:245\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(a, b, precision, preferred_element_type)\u001b[39m\n\u001b[32m    243\u001b[39m a = lax.squeeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[32m    244\u001b[39m b = lax.squeeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m out = lax.dot_general(\n\u001b[32m    246\u001b[39m   a, b, (((np.ndim(a) - \u001b[32m1\u001b[39m,), (np.ndim(b) - \u001b[32m1\u001b[39m - b_is_mat,)), (a_batch, b_batch)),\n\u001b[32m    247\u001b[39m   precision=precision, preferred_element_type=preferred_element_type)\n\u001b[32m    248\u001b[39m result = lax.transpose(out, perm)\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal._convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[31m[... skipping hidden 9 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\miniconda3\\envs\\JAX_ML_env_two\\Lib\\site-packages\\jax\\_src\\lax\\lax.py:5216\u001b[39m, in \u001b[36m_dot_general_shape_rule\u001b[39m\u001b[34m(lhs, rhs, dimension_numbers, precision, preferred_element_type, out_sharding)\u001b[39m\n\u001b[32m   5213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core.definitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[32m   5214\u001b[39m   msg = (\u001b[33m\"\u001b[39m\u001b[33mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5215\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m5216\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[32m   5218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs.shape, rhs.shape, dimension_numbers)\n",
      "\u001b[31mTypeError\u001b[39m: dot_general requires contracting dimensions to have the same shape, got (912,) and (1824,)."
     ]
    }
   ],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1], \n",
    "    dim_hidden1_in=128,\n",
    "    dim_hidden2_in=64, \n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    lambda_=lambda_\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(train_batches,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        \n",
    "        new_params, new_state, new_opt_state, loss_batch = training_step(\n",
    "            train_state.params,\n",
    "            train_state.state,\n",
    "            opt_state,\n",
    "            batch,\n",
    "            graph_def=train_state.graph_def,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=train_state.alpha,\n",
    "            gamma=train_state.gamma,\n",
    "            lambda_=train_state.lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e850b4",
   "metadata": {},
   "source": [
    "Final model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0738a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class ModelData(nnx.Object):\n",
    "    graph_def: Any\n",
    "    params: Any\n",
    "    state: Any\n",
    "    Dataset_parameters: Any\n",
    "    trained: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b354",
   "metadata": {},
   "source": [
    "Create Final model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78303138",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_trained = train_state.graph_def\n",
    "params_trained = train_state.params\n",
    "state_trained = train_state.state\n",
    "\n",
    "model_data = ModelData(\n",
    "    graph_def=graph_def_trained,\n",
    "    params=params_trained,\n",
    "    state=state_trained,\n",
    "    Dataset_parameters=Dataset_parameters,\n",
    "    trained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f93141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12654570e10>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.log10(jnp.array(loss_record)))\n",
    "#plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61baeb33",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_abs_error(pred,target):\n",
    "    n1 = pred.shape[0]\n",
    "    n2 = target.shape[0]\n",
    "\n",
    "    if n1 != n2:\n",
    "        raise(\"Error: inputs must have matching shape\")\n",
    "    \n",
    "    return (jnp.sum(jnp.abs(pred - target)) / n1)\n",
    "\n",
    "def test_model(model_data, test_batches*,loss_fn, alpha, gamma, lambda_):\n",
    "\n",
    "    trained = model_data.trained\n",
    "    if not trained:\n",
    "        raise TypeError(\"Model is untrained, please train the model before evaluation\")\n",
    "\n",
    "    test_graph_def = model_data.graph_def\n",
    "    test_params = model_data.params\n",
    "    test_state = model_data.state\n",
    "\n",
    "    test_model = nnx.merge(test_graph_def,test_params,test_state)\n",
    "\n",
    "    loss_test = 0.0\n",
    "    test_count = 0\n",
    "\n",
    "    for batch in test_batches:\n",
    "        displacements_test = batch['displacements']\n",
    "        e_target_test = batch['target_e']\n",
    "        e_prime_target_test = batch['target_e_prime']\n",
    "\n",
    "        e_target_test = unscale_data(e_target_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_target_test = unscale_data(e_prime_target_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        e_pred_test, e_prime_pred_test = test_model(displacements_test,data_params=model_data.Dataset_parameters['displacements'])\n",
    "\n",
    "        #displacements_test = unscale_data(displacements_test,data_params=Dataset_parameters['displacements'])\n",
    "        e_pred_test = unscale_data(e_pred_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_pred_test = unscale_data(e_prime_pred_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        batch_loss_test = loss_fn(\n",
    "            displacements_test,\n",
    "            e_target_test,\n",
    "            e_prime_target_test,\n",
    "            Model=test_model,\n",
    "            Dataset_parameters=model_data.Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        loss_test += batch_loss_test\n",
    "        test_count += 1\n",
    "\n",
    "        avg_e_abs_error = avg_abs_error(e_pred_test,e_target_test)\n",
    "        avg_e_prime_abs_error = avg_abs_error(e_prime_pred_test,e_prime_target_test)\n",
    "\n",
    "    avg_loss_test = loss_test / test_count\n",
    "    zero_val_e, _ = test_model(jnp.zeros_like(test_batches[0]['displacements']), data_params=model_data.Dataset_parameters['target_e'])\n",
    "    test_e_zero_error = avg_abs_error(zero_val_e, jnp.zeros_like(zero_val_e))\n",
    "\n",
    "    return avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3504",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average absolute error for e is 109.0950698852539 in the test set\n",
      "the average absolute error for e prime is 18414306.0 in the test set\n",
      "the absolute zero error for e is 0.21817588806152344 in the test set\n",
      "The average loss across the training set is 248372048.0\n",
      "The average absolute error for e is 80.87535858154297 in the training set\n",
      "the average absolute error for e prime is 14059826.0 in the training set\n",
      "the absolute zero error for e is 0.21817588806152344 in the training set\n"
     ]
    }
   ],
   "source": [
    "avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error = test_model(model_data,test_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    "avg_loss_training, avg_e_abs_error_training, avg_e_prime_abs_error_training, test_e_zero_error_training = test_model(model_data,train_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    " \n",
    "print(f\"The average absolute error for e is {avg_e_abs_error} in the test set\") \n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error} in the test set\") \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error} in the test set\") \n",
    "\n",
    "print(f\"The average loss across the training set is {avg_loss_test}\")\n",
    "print(f\"The average absolute error for e is {avg_e_abs_error_training} in the training set\")\n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error_training} in the training set\")  \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error_training} in the training set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
