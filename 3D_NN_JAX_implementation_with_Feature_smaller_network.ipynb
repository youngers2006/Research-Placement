{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc34597",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cae85666",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 1000\n",
    "alpha = 1.0\n",
    "gamma = 20.0\n",
    "lambda_ = 0.1\n",
    "Learn_Rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 40\n",
    "train_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2340, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(12340, 152, 3)\n",
      "(12340, 1)\n",
      "(12340, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)[0:2340]\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)[0:2340]\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)[0:2340]\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = jnp.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec14bee",
   "metadata": {},
   "source": [
    "Pre and post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6607d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data = data[:split_idx]\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "\n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']\n",
    "\n",
    "def add_square_feature(data,*,axis, feature_number):\n",
    "    new_feature = jnp.square(data)\n",
    "    new_data = jnp.concatenate([data,new_feature],axis=axis)\n",
    "    feature_number += 1\n",
    "    return new_data, feature_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset - Note: need to remove input scaling in the dataset as its done in the model, need to add a parameter calulator for the input that concatenates the square data then gets params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4221141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING RAW DATASET\n",
      "Key: 'displacements'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 912)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340,)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e_prime'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 456)\n",
      "  - Dtype: float32\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "input_dataset = input_dataset.reshape((input_dataset.shape[0],456))\n",
    "displacement_dim = input_dataset.shape[1]\n",
    "\n",
    "# add features\n",
    "num_features = 0\n",
    "input_dataset, num_features = add_square_feature(input_dataset,axis=1, feature_number=num_features)\n",
    "\n",
    "target_e_dataset = target_e_dataset.reshape((target_e_dataset.shape[0],))\n",
    "target_e_prime_dataset = target_e_prime_dataset.reshape((target_e_prime_dataset.shape[0],456))\n",
    "\n",
    "params_dict_displacement = mean_and_std_dev(input_dataset,train_split=train_split)\n",
    "params_dict_target_e = mean_and_std_dev(target_e_dataset,train_split=train_split)\n",
    "params_dict_target_e_prime = mean_and_std_dev(target_e_prime_dataset,train_split=train_split)\n",
    "\n",
    "input_dataset_scaled = scale_data(input_dataset,data_params=params_dict_displacement)\n",
    "target_e_dataset_scaled = scale_data(target_e_dataset, data_params=params_dict_target_e)\n",
    "target_e_prime_dataset_scaled = scale_data(target_e_prime_dataset, data_params=params_dict_target_e_prime)\n",
    "\n",
    "Dataset_parameters = {\n",
    "    'displacements':params_dict_displacement,\n",
    "    'target_e':params_dict_target_e,\n",
    "    'target_e_prime':params_dict_target_e_prime,\n",
    "    'num_features':num_features,\n",
    "    'standard_displacement_dim':displacement_dim\n",
    "}\n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset_scaled, \n",
    "    'target_e':target_e_dataset_scaled,\n",
    "    'target_e_prime':target_e_prime_dataset_scaled\n",
    "}\n",
    "\n",
    "print(\"INSPECTING RAW DATASET\")\n",
    "for key, value in Dataset.items():\n",
    "    print(f\"Key: '{key}'\")\n",
    "    print(f\"  - Type: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  - Shape: {value.shape}\")\n",
    "    else:\n",
    "        print(\"  - No shape attribute.\")\n",
    "    if hasattr(value, 'dtype'):\n",
    "        print(f\"  - Dtype: {value.dtype}\")\n",
    "print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b799cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1932328\n",
      "2.932326\n",
      "4.1916647\n"
     ]
    }
   ],
   "source": [
    "print(Dataset['displacements'][0][1])\n",
    "print(Dataset['target_e'][0])\n",
    "print(Dataset['target_e_prime'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.Module):\n",
    "    \"\"\"\n",
    "    Model architecture\n",
    "    Inputs: standardised displacements and all engineered features and the parameters of the dataset\n",
    "    Outputs: standardised energy value and standardised energy derivatives wrt each of the displacements\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in,rngs=rngs)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in,rngs=rngs)\n",
    "        self.output_layer = Linear(din=dim_hidden2_in,dout=dim_out,rngs=rngs)\n",
    "        self.silu = SiLU\n",
    "\n",
    "    def forwardPass(self,x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.output_layer(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "    def __call__(self,x_in,dataset_params):\n",
    "        \n",
    "        e = jax.vmap(self.forwardPass)(x_in)\n",
    "        dedx = jax.vmap(jax.grad(self.forwardPass))\n",
    "        e_prime_raw = dedx(x_in)\n",
    "        e_prime_raw_lin_ft = e_prime_raw[:, :456]\n",
    "\n",
    "        sigma_e = dataset_params['target_e']['std_dev']\n",
    "        sigma_x = dataset_params['displacements']['std_dev']\n",
    "        sigma_x_linear = sigma_x[:456]\n",
    "        mean_e_prime = dataset_params['target_e_prime']['mean']\n",
    "        sigma_e_prime = dataset_params['target_e_prime']['std_dev']\n",
    "\n",
    "        e_prime_physical = e_prime_raw_lin_ft * (sigma_e/sigma_x_linear)\n",
    "        e_prime = (e_prime_physical - mean_e_prime) / sigma_e_prime\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(x, Dataset_parameters)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean(optax.huber_loss(prediction_e_prime, target_e_prime))\n",
    "\n",
    "    mean_e = Dataset_parameters['target_e']['mean']\n",
    "    std_dev_e = Dataset_parameters['target_e']['std_dev']\n",
    "    target_zero = (0 - mean_e) / std_dev_e\n",
    "    \n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "    prediction_zero, _ = Model(x_zero, Dataset_parameters)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any \n",
    "    state: Any\n",
    "    alpha: float \n",
    "    gamma: float \n",
    "    lambda_: float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(params,state,opt_state,batch,*,graph_def,Dataset_parameters,alpha,gamma,lambda_):\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(params_,state_):\n",
    "        Model = nnx.merge(graph_def,params_,state_)\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=0)(params, state) \n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "\n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e88cb1",
   "metadata": {},
   "source": [
    "Batch Creator and test set creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9981b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_batch_dataset(dataset, batch_size, test_split=0.2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets, then yields batches for each.\n",
    "    Returns: (train_batches, test_batches).\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    split_idx = int(N * (1 - test_split))\n",
    "    train_idx = indices[:split_idx]\n",
    "    test_idx = indices[split_idx:]\n",
    "\n",
    "    def batch_indices(idx):\n",
    "        batch_num = len(idx) // batch_size\n",
    "        for i in range(batch_num):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            batch = {key: value[batch_idx] for key, value in dataset.items()}\n",
    "            yield batch\n",
    "\n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e467e7e",
   "metadata": {},
   "source": [
    "Create test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df10eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = split_and_batch_dataset(\n",
    "    Dataset, \n",
    "    Batch_size, \n",
    "    test_split=(1 - train_split), \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1], \n",
    "    dim_hidden1_in=128,\n",
    "    dim_hidden2_in=64, \n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    lambda_=lambda_\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(train_batches,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        \n",
    "        new_params, new_state, new_opt_state, loss_batch = training_step(\n",
    "            train_state.params,\n",
    "            train_state.state,\n",
    "            opt_state,\n",
    "            batch,\n",
    "            graph_def=train_state.graph_def,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=train_state.alpha,\n",
    "            gamma=train_state.gamma,\n",
    "            lambda_=train_state.lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e850b4",
   "metadata": {},
   "source": [
    "Final model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0738a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class ModelData(nnx.Object):\n",
    "    graph_def: Any\n",
    "    params: Any\n",
    "    state: Any\n",
    "    Dataset_parameters: Any\n",
    "    trained: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b354",
   "metadata": {},
   "source": [
    "Create Final model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78303138",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_trained = train_state.graph_def\n",
    "params_trained = train_state.params\n",
    "state_trained = train_state.state\n",
    "\n",
    "model_data = ModelData(\n",
    "    graph_def=graph_def_trained,\n",
    "    params=params_trained,\n",
    "    state=state_trained,\n",
    "    Dataset_parameters=Dataset_parameters,\n",
    "    trained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80f93141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1699e3b9310>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.log10(jnp.array(loss_record)))\n",
    "#plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61baeb33",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1645b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_abs_error(pred,target):\n",
    "    n1 = pred.shape[0]\n",
    "    n2 = target.shape[0]\n",
    "\n",
    "    if n1 != n2:\n",
    "        raise(\"Error: inputs must have matching shape\")\n",
    "    \n",
    "    return (jnp.sum(jnp.abs(pred - target)) / n1)\n",
    "\n",
    "def test_model(model_data, test_batches,*,loss_fn, alpha, gamma, lambda_):\n",
    "\n",
    "    trained = model_data.trained\n",
    "    if not trained:\n",
    "        raise TypeError(\"Model is untrained, please train the model before evaluation\")\n",
    "\n",
    "    test_graph_def = model_data.graph_def\n",
    "    test_params = model_data.params\n",
    "    test_state = model_data.state\n",
    "\n",
    "    test_model = nnx.merge(test_graph_def,test_params,test_state)\n",
    "\n",
    "    loss_test = 0.0\n",
    "    test_count = 0\n",
    "\n",
    "    for batch in test_batches:\n",
    "        displacements_test = batch['displacements']\n",
    "        e_target_test = batch['target_e']\n",
    "        e_prime_target_test = batch['target_e_prime']\n",
    "\n",
    "        e_target_test_US = unscale_data(e_target_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_target_test_US = unscale_data(e_prime_target_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        e_pred_test, e_prime_pred_test = test_model(displacements_test,dataset_params=model_data.Dataset_parameters)\n",
    "\n",
    "        #displacements_test = unscale_data(displacements_test,data_params=Dataset_parameters['displacements'])\n",
    "        e_pred_test_US = unscale_data(e_pred_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_pred_test_US = unscale_data(e_prime_pred_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        batch_loss_test = loss_fn(\n",
    "            displacements_test,\n",
    "            e_target_test,\n",
    "            e_prime_target_test,\n",
    "            Model=test_model,\n",
    "            Dataset_parameters=model_data.Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        loss_test += batch_loss_test\n",
    "        test_count += 1\n",
    "\n",
    "        avg_e_abs_error = avg_abs_error(e_pred_test_US,e_target_test_US)\n",
    "        avg_e_prime_abs_error = avg_abs_error(e_prime_pred_test_US,e_prime_target_test_US)\n",
    "\n",
    "    avg_loss_test = loss_test / test_count\n",
    "    zero_val_e, _ = test_model(scale_data(jnp.zeros_like(test_batches[0]['displacements']),data_params=model_data.Dataset_parameters['displacements']), dataset_params=model_data.Dataset_parameters)\n",
    "    zero_val_e = unscale_data(zero_val_e,data_params=model_data.Dataset_parameters['target_e'])\n",
    "    test_e_zero_error = avg_abs_error(zero_val_e, jnp.zeros_like(zero_val_e))\n",
    "\n",
    "    return avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3504",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1486d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average absolute error for e is 104.2488021850586 in the test set\n",
      "the average absolute error for e prime is 7874257.0 in the test set\n",
      "the absolute zero error for e is 6.932585716247559 in the test set\n",
      "The average loss across the training set is 9.165923118591309\n",
      "The average absolute error for e is 7.782227993011475 in the training set\n",
      "the average absolute error for e prime is 2897140.5 in the training set\n",
      "the absolute zero error for e is 6.932585716247559 in the training set\n"
     ]
    }
   ],
   "source": [
    "avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error = test_model(model_data,test_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    "avg_loss_training, avg_e_abs_error_training, avg_e_prime_abs_error_training, test_e_zero_error_training = test_model(model_data,train_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    " \n",
    "print(f\"The average absolute error for e is {avg_e_abs_error} in the test set\") \n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error} in the test set\") \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error} in the test set\") \n",
    "\n",
    "print(f\"The average loss across the training set is {avg_loss_test}\")\n",
    "print(f\"The average absolute error for e is {avg_e_abs_error_training} in the training set\")\n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error_training} in the training set\")  \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error_training} in the training set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
