{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2340, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(12340, 152, 3)\n",
      "(12340, 1)\n",
      "(12340, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)[0:2340]\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)[0:2340]\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)[0:2340]\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080cf8e",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa714ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10000\n",
    "alpha = 1.0\n",
    "gamma = 200.0\n",
    "lambda_ = 20.0\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 40\n",
    "train_split = 0.9\n",
    "steps_per_epoch = input_dataset.shape[0] // Batch_size\n",
    "Learn_Rate = optax.exponential_decay(\n",
    "    init_value=0.001,\n",
    "    transition_steps=steps_per_epoch * 5,\n",
    "    decay_rate=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = jnp.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec14bee",
   "metadata": {},
   "source": [
    "Pre and post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6607d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data = data[:split_idx]\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "\n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']\n",
    "\n",
    "def add_square_feature(data,*,axis, feature_number):\n",
    "    new_feature = jnp.square(data)\n",
    "    new_data = jnp.concatenate([data,new_feature],axis=axis)\n",
    "    feature_number += 1\n",
    "    return new_data, feature_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset - Note: need to remove input scaling in the dataset as its done in the model, need to add a parameter calulator for the input that concatenates the square data then gets params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4221141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING RAW DATASET\n",
      "Key: 'displacements'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 912)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340,)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e_prime'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 456)\n",
      "  - Dtype: float32\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "input_dataset = input_dataset.reshape((input_dataset.shape[0],456))\n",
    "displacement_dim = input_dataset.shape[1]\n",
    "\n",
    "# add features\n",
    "num_features = 0\n",
    "input_dataset, num_features = add_square_feature(input_dataset,axis=1, feature_number=num_features)\n",
    "\n",
    "target_e_dataset = target_e_dataset.reshape((target_e_dataset.shape[0],))\n",
    "target_e_prime_dataset = target_e_prime_dataset.reshape((target_e_prime_dataset.shape[0],456))\n",
    "\n",
    "params_dict_displacement = mean_and_std_dev(input_dataset,train_split=train_split)\n",
    "params_dict_target_e = mean_and_std_dev(target_e_dataset,train_split=train_split)\n",
    "params_dict_target_e_prime = mean_and_std_dev(target_e_prime_dataset,train_split=train_split)\n",
    "\n",
    "input_dataset_scaled = scale_data(input_dataset,data_params=params_dict_displacement)\n",
    "target_e_dataset_scaled = scale_data(target_e_dataset, data_params=params_dict_target_e)\n",
    "target_e_prime_dataset_scaled = scale_data(target_e_prime_dataset, data_params=params_dict_target_e_prime)\n",
    "\n",
    "Dataset_parameters = {\n",
    "    'displacements':params_dict_displacement,\n",
    "    'target_e':params_dict_target_e,\n",
    "    'target_e_prime':params_dict_target_e_prime,\n",
    "    'num_features':num_features,\n",
    "    'standard_displacement_dim':displacement_dim\n",
    "}\n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset_scaled, \n",
    "    'target_e':target_e_dataset_scaled,\n",
    "    'target_e_prime':target_e_prime_dataset_scaled\n",
    "}\n",
    "\n",
    "print(\"INSPECTING RAW DATASET\")\n",
    "for key, value in Dataset.items():\n",
    "    print(f\"Key: '{key}'\")\n",
    "    print(f\"  - Type: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  - Shape: {value.shape}\")\n",
    "    else:\n",
    "        print(\"  - No shape attribute.\")\n",
    "    if hasattr(value, 'dtype'):\n",
    "        print(f\"  - Dtype: {value.dtype}\")\n",
    "print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b799cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1932328\n",
      "2.932326\n",
      "4.1916647\n"
     ]
    }
   ],
   "source": [
    "print(Dataset['displacements'][0][1])\n",
    "print(Dataset['target_e'][0])\n",
    "print(Dataset['target_e_prime'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.Module):\n",
    "    \"\"\"\n",
    "    Model architecture\n",
    "    Inputs: standardised displacements and all engineered features and the parameters of the dataset\n",
    "    Outputs: standardised energy value and standardised energy derivatives wrt each of the displacements\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_hidden2_in: int, dim_hidden3_in: int, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in,rngs=rngs)\n",
    "        self.layer2 = Linear(din=dim_hidden1_in,dout=dim_hidden2_in,rngs=rngs)\n",
    "        self.layer3 = Linear(din=dim_hidden2_in,dout=dim_hidden3_in,rngs=rngs)\n",
    "        self.output_layer = Linear(din=dim_hidden3_in,dout=dim_out,rngs=rngs)\n",
    "        self.silu = SiLU\n",
    "\n",
    "    def forwardPass(self,x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.output_layer(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "    def __call__(self,x_in,dataset_params):\n",
    "        \n",
    "        e = jax.vmap(self.forwardPass)(x_in)\n",
    "        dedx = jax.vmap(jax.grad(self.forwardPass))\n",
    "        e_prime_raw = dedx(x_in)\n",
    "        e_prime_raw_lin_ft = e_prime_raw[:, :456]\n",
    "\n",
    "        sigma_e = dataset_params['target_e']['std_dev']\n",
    "        sigma_x = dataset_params['displacements']['std_dev']\n",
    "        sigma_x_linear = sigma_x[:456]\n",
    "        mean_e_prime = dataset_params['target_e_prime']['mean']\n",
    "        sigma_e_prime = dataset_params['target_e_prime']['std_dev']\n",
    "\n",
    "        e_prime_physical = e_prime_raw_lin_ft * (sigma_e/sigma_x_linear)\n",
    "        e_prime = (e_prime_physical - mean_e_prime) / sigma_e_prime\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_e, prediction_e_prime = Model(x, Dataset_parameters)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean(optax.huber_loss(prediction_e_prime, target_e_prime))\n",
    "\n",
    "    mean_e = Dataset_parameters['target_e']['mean']\n",
    "    std_dev_e = Dataset_parameters['target_e']['std_dev']\n",
    "    target_zero = (0 - mean_e) / std_dev_e\n",
    "    \n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "    prediction_zero, _ = Model(x_zero, Dataset_parameters)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any \n",
    "    state: Any\n",
    "    alpha: float \n",
    "    gamma: float \n",
    "    lambda_: float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(params,state,opt_state,batch,*,graph_def,Dataset_parameters,alpha,gamma,lambda_):\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(params_,state_):\n",
    "        Model = nnx.merge(graph_def,params_,state_)\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=0)(params, state) \n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "\n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e88cb1",
   "metadata": {},
   "source": [
    "Batch Creator and test set creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9981b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_batch_dataset(dataset, batch_size, test_split=0.2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets, then yields batches for each.\n",
    "    Returns: (train_batches, test_batches).\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    split_idx = int(N * (1 - test_split))\n",
    "    train_idx = indices[:split_idx]\n",
    "    test_idx = indices[split_idx:]\n",
    "\n",
    "    def batch_indices(idx):\n",
    "        batch_num = len(idx) // batch_size\n",
    "        for i in range(batch_num):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            batch = {key: value[batch_idx] for key, value in dataset.items()}\n",
    "            yield batch\n",
    "\n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e467e7e",
   "metadata": {},
   "source": [
    "Create test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "df10eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = split_and_batch_dataset(\n",
    "    Dataset, \n",
    "    Batch_size, \n",
    "    test_split=(1 - train_split), \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=input_dataset.shape[1], \n",
    "    dim_hidden1_in=512,\n",
    "    dim_hidden2_in=256, \n",
    "    dim_hidden3_in=128,\n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    lambda_=lambda_\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(train_batches,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        \n",
    "        new_params, new_state, new_opt_state, loss_batch = training_step(\n",
    "            train_state.params,\n",
    "            train_state.state,\n",
    "            opt_state,\n",
    "            batch,\n",
    "            graph_def=train_state.graph_def,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=train_state.alpha,\n",
    "            gamma=train_state.gamma,\n",
    "            lambda_=train_state.lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e850b4",
   "metadata": {},
   "source": [
    "Final model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0738a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class ModelData(nnx.Object):\n",
    "    graph_def: Any\n",
    "    params: Any\n",
    "    state: Any\n",
    "    Dataset_parameters: Any\n",
    "    trained: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b354",
   "metadata": {},
   "source": [
    "Create Final model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78303138",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_trained = train_state.graph_def\n",
    "params_trained = train_state.params\n",
    "state_trained = train_state.state\n",
    "\n",
    "model_data = ModelData(\n",
    "    graph_def=graph_def_trained,\n",
    "    params=params_trained,\n",
    "    state=state_trained,\n",
    "    Dataset_parameters=Dataset_parameters,\n",
    "    trained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80f93141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16985489e50>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.log10(jnp.array(loss_record)))\n",
    "#plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61baeb33",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1645b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_abs_error(pred,target):\n",
    "    n1 = pred.shape[0]\n",
    "    n2 = target.shape[0]\n",
    "\n",
    "    if n1 != n2:\n",
    "        raise(\"Error: inputs must have matching shape\")\n",
    "    \n",
    "    return (jnp.sum(jnp.abs(pred - target)) / n1)\n",
    "\n",
    "def test_model(model_data, test_batches,*,loss_fn, alpha, gamma, lambda_):\n",
    "\n",
    "    trained = model_data.trained\n",
    "    if not trained:\n",
    "        raise TypeError(\"Model is untrained, please train the model before evaluation\")\n",
    "\n",
    "    test_graph_def = model_data.graph_def\n",
    "    test_params = model_data.params\n",
    "    test_state = model_data.state\n",
    "\n",
    "    test_model = nnx.merge(test_graph_def,test_params,test_state)\n",
    "\n",
    "    loss_test = 0.0\n",
    "    test_count = 0\n",
    "\n",
    "    for batch in test_batches:\n",
    "        displacements_test = batch['displacements']\n",
    "        e_target_test = batch['target_e']\n",
    "        e_prime_target_test = batch['target_e_prime']\n",
    "\n",
    "        e_target_test_US = unscale_data(e_target_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_target_test_US = unscale_data(e_prime_target_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        e_pred_test, e_prime_pred_test = test_model(displacements_test,dataset_params=model_data.Dataset_parameters)\n",
    "\n",
    "        #displacements_test = unscale_data(displacements_test,data_params=Dataset_parameters['displacements'])\n",
    "        e_pred_test_US = unscale_data(e_pred_test,data_params=model_data.Dataset_parameters['target_e'])\n",
    "        e_prime_pred_test_US = unscale_data(e_prime_pred_test,data_params=model_data.Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        batch_loss_test = loss_fn(\n",
    "            displacements_test,\n",
    "            e_target_test,\n",
    "            e_prime_target_test,\n",
    "            Model=test_model,\n",
    "            Dataset_parameters=model_data.Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        loss_test += batch_loss_test\n",
    "        test_count += 1\n",
    "\n",
    "        avg_e_abs_error = avg_abs_error(e_pred_test_US,e_target_test_US)\n",
    "        avg_e_prime_abs_error = avg_abs_error(e_prime_pred_test_US,e_prime_target_test_US)\n",
    "\n",
    "    avg_loss_test = loss_test / test_count\n",
    "    zero_val_e, _ = test_model(scale_data(jnp.zeros_like(test_batches[0]['displacements']),data_params=model_data.Dataset_parameters['displacements']), dataset_params=model_data.Dataset_parameters)\n",
    "    zero_val_e = unscale_data(zero_val_e,data_params=model_data.Dataset_parameters['target_e'])\n",
    "    test_e_zero_error = avg_abs_error(zero_val_e, jnp.zeros_like(zero_val_e))\n",
    "\n",
    "    return avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3504",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1486d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average absolute error for e is 149.1311798095703 in the test set\n",
      "the average absolute error for e prime is 8545590.0 in the test set\n",
      "the absolute zero error for e is 29.8807315826416 in the test set\n",
      "The average loss across the training set is 52.74714660644531\n",
      "The average absolute error for e is 31.192428588867188 in the training set\n",
      "the average absolute error for e prime is 2575334.75 in the training set\n",
      "the absolute zero error for e is 29.8807315826416 in the training set\n"
     ]
    }
   ],
   "source": [
    "avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error = test_model(model_data,test_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    "avg_loss_training, avg_e_abs_error_training, avg_e_prime_abs_error_training, test_e_zero_error_training = test_model(model_data,train_batches,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    " \n",
    "print(f\"The average absolute error for e is {avg_e_abs_error} in the test set\") \n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error} in the test set\") \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error} in the test set\") \n",
    "\n",
    "print(f\"The average loss across the training set is {avg_loss_test}\")\n",
    "print(f\"The average absolute error for e is {avg_e_abs_error_training} in the training set\")\n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error_training} in the training set\")  \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error_training} in the training set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
