{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dd517",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19a8aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from flax import nnx\n",
    "from flax import struct\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc34597",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae85666",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 1000\n",
    "alpha = 1.0\n",
    "gamma = 0.4\n",
    "lambda_ = 0.1\n",
    "Learn_Rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "Batch_size = 40\n",
    "train_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5385e",
   "metadata": {},
   "source": [
    "Unpickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "002646d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2340, 152, 3)\n",
      "(10000, 152, 3)\n",
      "(10000,)\n",
      "(10000, 152, 3)\n",
      "(12340, 152, 3)\n",
      "(12340, 1)\n",
      "(12340, 152, 3)\n"
     ]
    }
   ],
   "source": [
    "# Due to errors I was experiencing this seems to be the quickest fix I could find to allow me to unpickle the data\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "\n",
    "fake_module = types.ModuleType(\"DataSetup\")\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "fake_module.DataStore = DataStore\n",
    "\n",
    "sys.modules[\"DataSetup\"] = fake_module\n",
    "\n",
    "data_file_1 = r\"C:\\Users\\samue\\Downloads\\Simulation.pickle\"\n",
    "data_file_2 = r\"C:\\Users\\samue\\Downloads\\Simulation 2.pickle\"\n",
    "\n",
    "with open(data_file_1,\"rb\") as f:\n",
    "    data_unpickled_1 = pickle.load(f)\n",
    "\n",
    "with open(data_file_2,\"rb\") as f:\n",
    "    data_unpickled_2 = pickle.load(f)\n",
    "\n",
    "_,data_object_1 = data_unpickled_1\n",
    "_,data_object_2 = data_unpickled_2\n",
    "\n",
    "input_dataset_1 = jnp.array(data_object_1.Indata)\n",
    "#data_index_1 = data_object_1.i\n",
    "e_dataset_1 = jnp.array(data_object_1.SE)\n",
    "e_prime_dataset_1 = jnp.array(data_object_1.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)\n",
    "#data_index_2 = data_object_2.i\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)\n",
    "\n",
    "input_dataset_2 = jnp.array(data_object_2.Indata)[0:2340]\n",
    "e_dataset_2 = jnp.array(data_object_2.SE)[0:2340]\n",
    "e_prime_dataset_2 = jnp.array(data_object_2.Jac)[0:2340]\n",
    "\n",
    "print(input_dataset_2.shape)\n",
    "print(input_dataset_1.shape)\n",
    "print(e_dataset_1.shape)\n",
    "print(e_prime_dataset_1.shape)\n",
    "\n",
    "input_dataset = jax.numpy.concatenate([input_dataset_1,input_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.concatenate([e_dataset_1, e_dataset_2],axis=0)\n",
    "target_e_dataset = jax.numpy.expand_dims(target_e_dataset,axis=1)\n",
    "target_e_prime_dataset = jax.numpy.concatenate([e_prime_dataset_1,e_prime_dataset_2],axis=0)\n",
    "\n",
    "print(input_dataset.shape)\n",
    "print(target_e_dataset.shape)\n",
    "print(target_e_prime_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e5ebb",
   "metadata": {},
   "source": [
    "Redimensionalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb876813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redimensionalise(self):\n",
    "    self.Disp = jnp.zeros((self.Dims,self.Dims,self.Dims,3))\n",
    "    m = 0\n",
    "    for i in range(self.Dims):\n",
    "        for j in range(self.Dims):\n",
    "            for k in range(self.Dims):\n",
    "                if self.xInMesh[0][i,j,k] == 0 or self.xInMesh[0][i,j,k] == 1 or self.xInMesh[1][i,j,k] == 0 or self.xInMesh[1][i,j,k] == 1 or self.xInMesh[2][i,j,k] == 0 or self.xInMesh[2][i,j,k] == 1:\n",
    "                    self.Disp[i,j,k,:] = self.RandDisp[self.Index,m,:]\n",
    "                    m = m +1\n",
    "    return self.Disp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53d879",
   "metadata": {},
   "source": [
    "RNG key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "debbce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # This can be changed but is here to make the results easy to reproduce\n",
    "base_key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(base_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec14bee",
   "metadata": {},
   "source": [
    "Pre and post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6607d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std_dev(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data = data[:split_idx]\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def mean_and_std_dev_square_feature(data,*,train_split):\n",
    "    split_idx = int(data.shape[0] * train_split)\n",
    "    train_data_init = data[:split_idx]\n",
    "\n",
    "    additional_feature = jnp.square(train_data_init)\n",
    "\n",
    "    train_data = jnp.concatenate([train_data_init,additional_feature],axis=1)\n",
    "    \n",
    "    mean = jnp.mean(train_data, axis=0)\n",
    "    std_dev = jnp.std(train_data, axis=0)\n",
    "    return {'mean':mean, 'std_dev':std_dev}\n",
    "\n",
    "def scale_data(data,*, data_params):\n",
    "    return (data - data_params['mean']) / data_params['std_dev']\n",
    "    \n",
    "\n",
    "def unscale_data(data,*,data_params):\n",
    "    return (data * data_params['std_dev']) + data_params['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328deec4",
   "metadata": {},
   "source": [
    "Dataset - Note: need to remove input scaling in the dataset as its done in the model, need to add a parameter calulator for the input that concatenates the square data then gets params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4221141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING RAW DATASET\n",
      "Key: 'displacements'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 456)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340,)\n",
      "  - Dtype: float32\n",
      "Key: 'target_e_prime'\n",
      "  - Type: <class 'jaxlib._jax.ArrayImpl'>\n",
      "  - Shape: (12340, 456)\n",
      "  - Dtype: float32\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_num = input_dataset.shape[0] // Batch_size\n",
    "\n",
    "input_dataset = input_dataset.reshape((input_dataset.shape[0],456))\n",
    "target_e_dataset = target_e_dataset.reshape((target_e_dataset.shape[0],))\n",
    "target_e_prime_dataset = target_e_prime_dataset.reshape((target_e_prime_dataset.shape[0],456))\n",
    "\n",
    "params_dict_displacement = mean_and_std_dev_square_feature(input_dataset,train_split=train_split)\n",
    "params_dict_target_e = mean_and_std_dev(target_e_dataset,train_split=train_split)\n",
    "params_dict_target_e_prime = mean_and_std_dev(target_e_prime_dataset,train_split=train_split)\n",
    "\n",
    "target_e_dataset_scaled = scale_data(target_e_dataset, data_params=params_dict_target_e)\n",
    "target_e_prime_dataset_scaled = scale_data(target_e_prime_dataset, data_params=params_dict_target_e_prime)\n",
    "\n",
    "Dataset_parameters = {\n",
    "    'displacements':params_dict_displacement,\n",
    "    'target_e':params_dict_target_e,\n",
    "    'target_e_prime':params_dict_target_e_prime\n",
    "}\n",
    "\n",
    "Dataset = {\n",
    "    'displacements':input_dataset, # Dataset not scaled as its scaled in the model\n",
    "    'target_e':target_e_dataset_scaled,\n",
    "    'target_e_prime':target_e_prime_dataset_scaled\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print(\"INSPECTING RAW DATASET\")\n",
    "for key, value in Dataset.items():\n",
    "    print(f\"Key: '{key}'\")\n",
    "    print(f\"  - Type: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  - Shape: {value.shape}\")\n",
    "    else:\n",
    "        print(\"  - No shape attribute.\")\n",
    "    if hasattr(value, 'dtype'):\n",
    "        print(f\"  - Dtype: {value.dtype}\")\n",
    "print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b799cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034145229\n",
      "2.932326\n",
      "4.1916647\n"
     ]
    }
   ],
   "source": [
    "print(Dataset['displacements'][0][1])\n",
    "print(Dataset['target_e'][0])\n",
    "print(Dataset['target_e_prime'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c7c2",
   "metadata": {},
   "source": [
    "Node Classes and Acivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a77bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "    \"\"\"Linear node for neural network\"\"\"\n",
    "\n",
    "    def __init__(self,din: int,dout: int,*,rngs: nnx.Rngs):\n",
    "        key = rngs.params()\n",
    "        self.W = nnx.Param(jax.random.uniform(key=key, shape=(din,dout)))\n",
    "        self.b = nnx.Param(jnp.zeros(shape=(dout,)))\n",
    "        self.din, self.dout = din, dout\n",
    "\n",
    "    def __call__(self,x: jax.Array):\n",
    "        return(x @ self.W + self.b)\n",
    "    \n",
    "def SiLU(x: jax.Array):\n",
    "    \"\"\"Sigmoid Weighted Linear Unit activation function\"\"\"\n",
    "    return x * jax.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26f9bc",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59bfbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class energy_prediction(nnx.Module):\n",
    "    \"\"\"Model architecture\"\"\"\n",
    "\n",
    "    def __init__(self,dim_in: int, dim_hidden1_in: int, dim_out: int,*,rngs: nnx.Rngs):\n",
    "        self.layer1 = Linear(din=dim_in,dout=dim_hidden1_in,rngs=rngs)\n",
    "        self.output_layer = Linear(din=dim_hidden1_in,dout=dim_out,rngs=rngs)\n",
    "        self.silu = SiLU\n",
    "        \n",
    "    def __call__(self,x_in,data_params):\n",
    "        # pass to calculate e\n",
    "        def forwardPass(x_init,data_params):\n",
    "            x_ft = jnp.square(x_init)\n",
    "            x_combined = jnp.concatenate([x_init, x_ft])\n",
    "\n",
    "            def scale_data(data,*, data_params):\n",
    "                return (data - data_params['mean']) / data_params['std_dev']\n",
    "            \n",
    "            x = scale_data(x_combined,data_params=data_params)\n",
    "\n",
    "            x = self.layer1(x)\n",
    "            x = self.silu(x)\n",
    "            x = self.output_layer(x)\n",
    "            return x.squeeze()\n",
    "        \n",
    "        e = jax.vmap(forwardPass, in_axes=(0, None))(x_in, data_params)\n",
    "        dedx = jax.vmap(jax.grad(forwardPass,argnums=(0)), in_axes=(0, None))\n",
    "        e_prime = dedx(x_in, data_params)\n",
    "\n",
    "        return e, e_prime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc036a78",
   "metadata": {},
   "source": [
    "Define optimiser and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f469e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optax.adam(learning_rate=Learn_Rate, b1=beta_1, b2=beta_2)\n",
    "\n",
    "def loss_fn(x: jax.Array, target_e, target_e_prime,*, Model, Dataset_parameters, alpha, gamma, lam): \n",
    "    \"\"\"\n",
    "    Calculates the loss of a model, works to minimise the mean square error of both \n",
    "    the strain energy prediction and the strain energy derivative prediction,\n",
    "    whilst forcing the function through zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_params = Dataset_parameters['displacements']\n",
    "    prediction_e, prediction_e_prime = Model(x, data_params)\n",
    "    loss_e = jnp.mean((prediction_e - target_e)**2)\n",
    "    loss_e_prime = jnp.mean((prediction_e_prime - target_e_prime)**2)\n",
    "\n",
    "    target_zero = 0\n",
    "    x_zero = jnp.zeros(x[0].shape)\n",
    "    x_zero = jnp.expand_dims(x_zero, axis=0)\n",
    "    prediction_zero, _ = Model(x_zero, data_params)\n",
    "    loss_zero = jnp.mean((prediction_zero - target_zero)**2)\n",
    "\n",
    "    return (alpha * loss_e + gamma * loss_e_prime + lam * loss_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57659f0",
   "metadata": {},
   "source": [
    "Train State Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b764c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class TrainState(nnx.Object):\n",
    "    params: Any\n",
    "    graph_def: Any \n",
    "    state: Any\n",
    "    alpha: float \n",
    "    gamma: float \n",
    "    lambda_: float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118860",
   "metadata": {},
   "source": [
    "Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da6228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def training_step(params,state,opt_state,batch,*,graph_def,Dataset_parameters,alpha,gamma,lambda_):\n",
    "\n",
    "    disp_in = batch['displacements']\n",
    "    e_target = batch['target_e']\n",
    "    e_prime_target = batch['target_e_prime']\n",
    "\n",
    "    def wrapped_loss_fn(params_,state_):\n",
    "        Model = nnx.merge(graph_def,params_,state_)\n",
    "        loss = loss_fn(\n",
    "            disp_in,\n",
    "            e_target,\n",
    "            e_prime_target,\n",
    "            Model=Model,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(wrapped_loss_fn, argnums=0)(params, state) \n",
    "    updates, new_opt_state = optimiser.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    new_state = state\n",
    "\n",
    "    return new_params, new_state, new_opt_state, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e88cb1",
   "metadata": {},
   "source": [
    "Batch Creator and test set creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9981b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_batch_dataset(dataset, batch_size, test_split=0.2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets, then yields batches for each.\n",
    "    Returns: (train_batches, test_batches).\n",
    "    \"\"\"\n",
    "    N = dataset['displacements'].shape[0]\n",
    "    indices = jnp.arange(N)\n",
    "    if shuffle:\n",
    "        indices = jax.random.permutation(jax.random.PRNGKey(0), indices)\n",
    "    split_idx = int(N * (1 - test_split))\n",
    "    train_idx = indices[:split_idx]\n",
    "    test_idx = indices[split_idx:]\n",
    "\n",
    "    def batch_indices(idx):\n",
    "        batch_num = len(idx) // batch_size\n",
    "        for i in range(batch_num):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch_idx = idx[start:end]\n",
    "            batch = {key: value[batch_idx] for key, value in dataset.items()}\n",
    "            yield batch\n",
    "\n",
    "    train_batches = list(batch_indices(train_idx))\n",
    "    test_batches = list(batch_indices(test_idx))\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e467e7e",
   "metadata": {},
   "source": [
    "Create test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df10eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = split_and_batch_dataset(\n",
    "    Dataset, \n",
    "    Batch_size, \n",
    "    test_split=(1 - train_split), \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df560003",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23fdd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "# Instantiate energy prediction NN\n",
    "Model = energy_prediction(\n",
    "    dim_in=(input_dataset.shape[1] * 2), \n",
    "    dim_hidden1_in=512,\n",
    "    dim_out=1,\n",
    "    rngs=rngs\n",
    ")\n",
    "\n",
    "graph_def,params,state = nnx.split(Model,nnx.Param,nnx.State)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_state = TrainState(\n",
    "    graph_def=graph_def,\n",
    "    params=params,\n",
    "    state=state,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    lambda_=lambda_\n",
    "    )\n",
    "\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch in tqdm(train_batches,desc=f\"Epoch {epoch}/{Epochs}\", leave=False):\n",
    "        \n",
    "        new_params, new_state, new_opt_state, loss_batch = training_step(\n",
    "            train_state.params,\n",
    "            train_state.state,\n",
    "            opt_state,\n",
    "            batch,\n",
    "            graph_def=train_state.graph_def,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=train_state.alpha,\n",
    "            gamma=train_state.gamma,\n",
    "            lambda_=train_state.lambda_\n",
    "        )\n",
    "\n",
    "        opt_state = new_opt_state\n",
    "        train_state.params = new_params\n",
    "        train_state.state = new_state\n",
    "\n",
    "        running_loss += loss_batch\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = avg_loss = running_loss / batch_count if batch_count > 0 else 0.0\n",
    "    loss_record.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e850b4",
   "metadata": {},
   "source": [
    "Final model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0738a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.dataclass\n",
    "class ModelData(nnx.Object):\n",
    "    graph_def: Any\n",
    "    params: Any\n",
    "    state: Any\n",
    "    trained: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b354",
   "metadata": {},
   "source": [
    "Create Final model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78303138",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_trained = train_state.graph_def\n",
    "params_trained = train_state.params\n",
    "state_trained = train_state.state\n",
    "\n",
    "model_data = ModelData(\n",
    "    graph_def=graph_def_trained,\n",
    "    params=params_trained,\n",
    "    state = state_trained,\n",
    "    trained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc294f4",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80f93141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2073dc4a490>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jnp.log10(jnp.array(loss_record)))\n",
    "#plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61baeb33",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1645b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_abs_error(pred,target):\n",
    "    n1 = pred.shape[0]\n",
    "    n2 = target.shape[0]\n",
    "\n",
    "    if n1 != n2:\n",
    "        raise(\"Error: inputs must have matching shape\")\n",
    "    \n",
    "    return (jnp.sum(jnp.abs(pred - target)) / n1)\n",
    "\n",
    "def test_model(model_data, test_batches, Dataset_parameters,*,loss_fn, alpha, gamma, lambda_):\n",
    "\n",
    "    trained = model_data.trained\n",
    "    if not trained:\n",
    "        raise TypeError(\"Model is untrained, please train the model before evaluation\")\n",
    "\n",
    "    test_graph_def = model_data.graph_def\n",
    "    test_params = model_data.params\n",
    "    test_state = model_data.state\n",
    "\n",
    "    test_model = nnx.merge(test_graph_def,test_params,test_state)\n",
    "\n",
    "    loss_test = 0.0\n",
    "    test_count = 0\n",
    "\n",
    "    for batch in test_batches:\n",
    "        displacements_test = batch['displacements']\n",
    "        e_target_test = batch['target_e']\n",
    "        e_prime_target_test = batch['target_e_prime']\n",
    "\n",
    "        e_target_test = unscale_data(e_target_test,data_params=Dataset_parameters['target_e'])\n",
    "        e_prime_target_test = unscale_data(e_prime_target_test,data_params=Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        e_pred_test, e_prime_pred_test = test_model(displacements_test,data_params=Dataset_parameters['displacements'])\n",
    "\n",
    "        #displacements_test = unscale_data(displacements_test,data_params=Dataset_parameters['displacements'])\n",
    "        e_pred_test = unscale_data(e_pred_test,data_params=Dataset_parameters['target_e'])\n",
    "        e_prime_pred_test = unscale_data(e_prime_pred_test,data_params=Dataset_parameters['target_e_prime'])\n",
    "\n",
    "        batch_loss_test = loss_fn(\n",
    "            displacements_test,\n",
    "            e_target_test,\n",
    "            e_prime_target_test,\n",
    "            Model=test_model,\n",
    "            Dataset_parameters=Dataset_parameters,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            lam=lambda_\n",
    "        )\n",
    "\n",
    "        loss_test += batch_loss_test\n",
    "        test_count += 1\n",
    "\n",
    "        avg_e_abs_error = avg_abs_error(e_pred_test,e_target_test)\n",
    "        avg_e_prime_abs_error = avg_abs_error(e_prime_pred_test,e_prime_target_test)\n",
    "\n",
    "    avg_loss_test = loss_test / test_count\n",
    "    zero_val_e, _ = test_model(jnp.zeros_like(test_batches[0]['displacements']), data_params=Dataset_parameters['target_e'])\n",
    "    test_e_zero_error = avg_abs_error(zero_val_e, jnp.zeros_like(zero_val_e))\n",
    "\n",
    "    return avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3504",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1486d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average absolute error for e is 104.40093994140625 in the test set\n",
      "the average absolute error for e prime is 19316326.0 in the test set\n",
      "the absolute zero error for e is 0.1285884529352188 in the test set\n",
      "The average loss across the training set is 248368080.0\n",
      "The average absolute error for e is 48.02425003051758 in the training set\n",
      "the average absolute error for e prime is 4846356.5 in the training set\n",
      "the absolute zero error for e is 0.1285884529352188 in the training set\n"
     ]
    }
   ],
   "source": [
    "avg_loss_test, avg_e_abs_error, avg_e_prime_abs_error, test_e_zero_error = test_model(model_data,test_batches, Dataset_parameters,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    "avg_loss_training, avg_e_abs_error_training, avg_e_prime_abs_error_training, test_e_zero_error_training = test_model(model_data,train_batches, Dataset_parameters,loss_fn=loss_fn,alpha=alpha,gamma=gamma,lambda_=lambda_)\n",
    " \n",
    "print(f\"The average absolute error for e is {avg_e_abs_error} in the test set\") \n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error} in the test set\") \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error} in the test set\") \n",
    "\n",
    "print(f\"The average loss across the training set is {avg_loss_test}\")\n",
    "print(f\"The average absolute error for e is {avg_e_abs_error_training} in the training set\")\n",
    "print(f\"the average absolute error for e prime is {avg_e_prime_abs_error_training} in the training set\")  \n",
    "print(f\"the absolute zero error for e is {test_e_zero_error_training} in the training set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX_ML_env_two",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
